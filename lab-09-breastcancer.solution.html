<!DOCTYPE html>
<html lang="en"><head>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="lab-09-breastcancer.solution_files/libs/quarto-html/tabby.min.js"></script>
<script src="lab-09-breastcancer.solution_files/libs/quarto-html/popper.min.js"></script>
<script src="lab-09-breastcancer.solution_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="lab-09-breastcancer.solution_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="lab-09-breastcancer.solution_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="lab-09-breastcancer.solution_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="lab-09-breastcancer.solution_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.4.549">

  <meta name="author" content="Matteo Francia   DISI — University of Bologna   m.francia@unibo.it">
  <title>Machine Learning and Data Mining (Module 2)</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="lab-09-breastcancer.solution_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="lab-09-breastcancer.solution_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="lab-09-breastcancer.solution_files/libs/revealjs/dist/theme/quarto.css">
  <link href="lab-09-breastcancer.solution_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="lab-09-breastcancer.solution_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="lab-09-breastcancer.solution_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="lab-09-breastcancer.solution_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
  
  <script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Machine Learning and Data Mining (Module 2)</h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Matteo Francia <br> DISI — University of Bologna <br> m.francia@unibo.it 
</div>
</div>
</div>

</section>
<section class="slide level2">

<p><a href="https://colab.research.google.com/github/w4bo/AA2425-unibo-mldm/blob/master/slides/lab-09-breastcancer.solution.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></p>
</section>
<section id="the-breastcancer-challenge" class="title-slide slide level1 center">
<h1>The <code>BreastCancer</code> challenge</h1>
<p><strong>Goal</strong>: it is your job to predict the <code>diagnosis</code> for each data item.</p>
<p><strong>Metric</strong>: submissions are evaluated using the accuracy score.</p>
<ul>
<li>When splitting train and test datasets, the test dataset should contain 30% of the data.</li>
</ul>
<p><strong>Requirements</strong>: you are allowed to use <code>numpy</code>, <code>pandas</code>, <code>matplotlib</code>, <code>sns</code>, and <code>sklearn</code> Python libraries.</p>
<ol type="1">
<li>You can import any model from <code>sk-learn</code>.</li>
<li>Try <code>sk-learn</code> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html">pipelines</a></li>
<li>Explore AutoML with <code>FLAML</code></li>
</ol>
</section>

<section id="setup" class="title-slide slide level1 center">
<h1>Setup</h1>
<div id="cell-4" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:06:43.853041Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:06:43.852592Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:06:44.907780Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:06:44.907288Z&quot;}" data-execution_count="2">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb1-1"><a href=""></a><span class="co"># Import the libraries used for machine learning</span></span>
<span id="cb1-2"><a href=""></a><span class="im">import</span> numpy <span class="im">as</span> np  <span class="co"># linear algebra</span></span>
<span id="cb1-3"><a href=""></a><span class="im">import</span> pandas <span class="im">as</span> pd  <span class="co"># data processing, CSV file I/O (e.g. pd.read_csv), data manipulation as in SQL</span></span>
<span id="cb1-4"><a href=""></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt  <span class="co"># used for plotting </span></span>
<span id="cb1-5"><a href=""></a><span class="im">import</span> seaborn <span class="im">as</span> sns   <span class="co"># used for plotting</span></span>
<span id="cb1-6"><a href=""></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split  <span class="co">#  split the data into training and test</span></span>
<span id="cb1-7"><a href=""></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier  <span class="co"># import a machine learning model</span></span>
<span id="cb1-8"><a href=""></a><span class="im">from</span> sklearn <span class="im">import</span> metrics  <span class="co"># check the error and accuracy of the model</span></span>
<span id="cb1-9"><a href=""></a></span>
<span id="cb1-10"><a href=""></a><span class="co"># SEED all random generators</span></span>
<span id="cb1-11"><a href=""></a><span class="im">import</span> random</span>
<span id="cb1-12"><a href=""></a><span class="im">import</span> os</span>
<span id="cb1-13"><a href=""></a>seed <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb1-14"><a href=""></a>random.seed(seed)</span>
<span id="cb1-15"><a href=""></a>os.environ[<span class="st">'PYTHONHASHSEED'</span>] <span class="op">=</span> <span class="bu">str</span>(seed)</span>
<span id="cb1-16"><a href=""></a>np.random.seed(seed)</span>
<span id="cb1-17"><a href=""></a></span>
<span id="cb1-18"><a href=""></a><span class="co"># read the data</span></span>
<span id="cb1-19"><a href=""></a>df <span class="op">=</span> pd.read_csv(<span class="st">"https://raw.githubusercontent.com/w4bo/teaching-handsondatapipelines/main/materials/datasets/breastcancer.csv"</span>)</span></code></pre></div>
</details>
</div>
</section>

<section id="data-understanding" class="title-slide slide level1 center">
<h1>Data understanding</h1>
<p>Hints</p>
<ul>
<li>There are 569 observations with 30 features each</li>
<li>Each observation is labelled with a <code>diagnosis</code></li>
</ul>
<div id="cell-6" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:06:44.910033Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:06:44.909687Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:06:44.931346Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:06:44.930774Z&quot;}" data-execution_count="3">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb2-1"><a href=""></a>df</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="3">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">diagnosis</th>
<th data-quarto-table-cell-role="th">radius_mean</th>
<th data-quarto-table-cell-role="th">texture_mean</th>
<th data-quarto-table-cell-role="th">perimeter_mean</th>
<th data-quarto-table-cell-role="th">area_mean</th>
<th data-quarto-table-cell-role="th">smoothness_mean</th>
<th data-quarto-table-cell-role="th">compactness_mean</th>
<th data-quarto-table-cell-role="th">concavity_mean</th>
<th data-quarto-table-cell-role="th">concave points_mean</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">texture_worst</th>
<th data-quarto-table-cell-role="th">perimeter_worst</th>
<th data-quarto-table-cell-role="th">area_worst</th>
<th data-quarto-table-cell-role="th">smoothness_worst</th>
<th data-quarto-table-cell-role="th">compactness_worst</th>
<th data-quarto-table-cell-role="th">concavity_worst</th>
<th data-quarto-table-cell-role="th">concave points_worst</th>
<th data-quarto-table-cell-role="th">symmetry_worst</th>
<th data-quarto-table-cell-role="th">fractal_dimension_worst</th>
<th data-quarto-table-cell-role="th">Unnamed: 32</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>842302</td>
<td>M</td>
<td>17.99</td>
<td>10.38</td>
<td>122.80</td>
<td>1001.0</td>
<td>0.11840</td>
<td>0.27760</td>
<td>0.30010</td>
<td>0.14710</td>
<td>...</td>
<td>17.33</td>
<td>184.60</td>
<td>2019.0</td>
<td>0.16220</td>
<td>0.66560</td>
<td>0.7119</td>
<td>0.2654</td>
<td>0.4601</td>
<td>0.11890</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>842517</td>
<td>M</td>
<td>20.57</td>
<td>17.77</td>
<td>132.90</td>
<td>1326.0</td>
<td>0.08474</td>
<td>0.07864</td>
<td>0.08690</td>
<td>0.07017</td>
<td>...</td>
<td>23.41</td>
<td>158.80</td>
<td>1956.0</td>
<td>0.12380</td>
<td>0.18660</td>
<td>0.2416</td>
<td>0.1860</td>
<td>0.2750</td>
<td>0.08902</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>84300903</td>
<td>M</td>
<td>19.69</td>
<td>21.25</td>
<td>130.00</td>
<td>1203.0</td>
<td>0.10960</td>
<td>0.15990</td>
<td>0.19740</td>
<td>0.12790</td>
<td>...</td>
<td>25.53</td>
<td>152.50</td>
<td>1709.0</td>
<td>0.14440</td>
<td>0.42450</td>
<td>0.4504</td>
<td>0.2430</td>
<td>0.3613</td>
<td>0.08758</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>84348301</td>
<td>M</td>
<td>11.42</td>
<td>20.38</td>
<td>77.58</td>
<td>386.1</td>
<td>0.14250</td>
<td>0.28390</td>
<td>0.24140</td>
<td>0.10520</td>
<td>...</td>
<td>26.50</td>
<td>98.87</td>
<td>567.7</td>
<td>0.20980</td>
<td>0.86630</td>
<td>0.6869</td>
<td>0.2575</td>
<td>0.6638</td>
<td>0.17300</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>84358402</td>
<td>M</td>
<td>20.29</td>
<td>14.34</td>
<td>135.10</td>
<td>1297.0</td>
<td>0.10030</td>
<td>0.13280</td>
<td>0.19800</td>
<td>0.10430</td>
<td>...</td>
<td>16.67</td>
<td>152.20</td>
<td>1575.0</td>
<td>0.13740</td>
<td>0.20500</td>
<td>0.4000</td>
<td>0.1625</td>
<td>0.2364</td>
<td>0.07678</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">564</td>
<td>926424</td>
<td>M</td>
<td>21.56</td>
<td>22.39</td>
<td>142.00</td>
<td>1479.0</td>
<td>0.11100</td>
<td>0.11590</td>
<td>0.24390</td>
<td>0.13890</td>
<td>...</td>
<td>26.40</td>
<td>166.10</td>
<td>2027.0</td>
<td>0.14100</td>
<td>0.21130</td>
<td>0.4107</td>
<td>0.2216</td>
<td>0.2060</td>
<td>0.07115</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">565</td>
<td>926682</td>
<td>M</td>
<td>20.13</td>
<td>28.25</td>
<td>131.20</td>
<td>1261.0</td>
<td>0.09780</td>
<td>0.10340</td>
<td>0.14400</td>
<td>0.09791</td>
<td>...</td>
<td>38.25</td>
<td>155.00</td>
<td>1731.0</td>
<td>0.11660</td>
<td>0.19220</td>
<td>0.3215</td>
<td>0.1628</td>
<td>0.2572</td>
<td>0.06637</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">566</td>
<td>926954</td>
<td>M</td>
<td>16.60</td>
<td>28.08</td>
<td>108.30</td>
<td>858.1</td>
<td>0.08455</td>
<td>0.10230</td>
<td>0.09251</td>
<td>0.05302</td>
<td>...</td>
<td>34.12</td>
<td>126.70</td>
<td>1124.0</td>
<td>0.11390</td>
<td>0.30940</td>
<td>0.3403</td>
<td>0.1418</td>
<td>0.2218</td>
<td>0.07820</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">567</td>
<td>927241</td>
<td>M</td>
<td>20.60</td>
<td>29.33</td>
<td>140.10</td>
<td>1265.0</td>
<td>0.11780</td>
<td>0.27700</td>
<td>0.35140</td>
<td>0.15200</td>
<td>...</td>
<td>39.42</td>
<td>184.60</td>
<td>1821.0</td>
<td>0.16500</td>
<td>0.86810</td>
<td>0.9387</td>
<td>0.2650</td>
<td>0.4087</td>
<td>0.12400</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">568</td>
<td>92751</td>
<td>B</td>
<td>7.76</td>
<td>24.54</td>
<td>47.92</td>
<td>181.0</td>
<td>0.05263</td>
<td>0.04362</td>
<td>0.00000</td>
<td>0.00000</td>
<td>...</td>
<td>30.37</td>
<td>59.16</td>
<td>268.6</td>
<td>0.08996</td>
<td>0.06444</td>
<td>0.0000</td>
<td>0.0000</td>
<td>0.2871</td>
<td>0.07039</td>
<td>NaN</td>
</tr>
</tbody>
</table>

<p>569 rows × 33 columns</p>
</div>
</div>
</div>
</section>

<section id="data-profiling" class="title-slide slide level1 center">
<h1>Data profiling</h1>
<div id="cell-8" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:06:44.933328Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:06:44.932965Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:06:44.940722Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:06:44.940162Z&quot;}" data-execution_count="4">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb3-1"><a href=""></a>df.info()</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 569 entries, 0 to 568
Data columns (total 33 columns):
 #   Column                   Non-Null Count  Dtype  
---  ------                   --------------  -----  
 0   id                       569 non-null    int64  
 1   diagnosis                569 non-null    object 
 2   radius_mean              569 non-null    float64
 3   texture_mean             569 non-null    float64
 4   perimeter_mean           569 non-null    float64
 5   area_mean                569 non-null    float64
 6   smoothness_mean          569 non-null    float64
 7   compactness_mean         569 non-null    float64
 8   concavity_mean           569 non-null    float64
 9   concave points_mean      569 non-null    float64
 10  symmetry_mean            569 non-null    float64
 11  fractal_dimension_mean   569 non-null    float64
 12  radius_se                569 non-null    float64
 13  texture_se               569 non-null    float64
 14  perimeter_se             569 non-null    float64
 15  area_se                  569 non-null    float64
 16  smoothness_se            569 non-null    float64
 17  compactness_se           569 non-null    float64
 18  concavity_se             569 non-null    float64
 19  concave points_se        569 non-null    float64
 20  symmetry_se              569 non-null    float64
 21  fractal_dimension_se     569 non-null    float64
 22  radius_worst             569 non-null    float64
 23  texture_worst            569 non-null    float64
 24  perimeter_worst          569 non-null    float64
 25  area_worst               569 non-null    float64
 26  smoothness_worst         569 non-null    float64
 27  compactness_worst        569 non-null    float64
 28  concavity_worst          569 non-null    float64
 29  concave points_worst     569 non-null    float64
 30  symmetry_worst           569 non-null    float64
 31  fractal_dimension_worst  569 non-null    float64
 32  Unnamed: 32              0 non-null      float64
dtypes: float64(31), int64(1), object(1)
memory usage: 146.8+ KB</code></pre>
</div>
</div>
</section>

<section id="feature-semantics" class="title-slide slide level1 center">
<h1>Feature semantics</h1>
<p>Hint:</p>
<ul>
<li><code>id</code> of the observation</li>
<li><code>diagnosis</code> (M = malignant, B = benign)</li>
<li>Ten real-valued features are computed for each cell nucleus:
<ul>
<li><code>radius</code> (mean of distances from center to points on the perimeter)</li>
<li><code>texture</code> (standard deviation of gray-scale values)</li>
<li><code>perimeter</code></li>
<li><code>area</code></li>
<li><code>smoothness</code> (local variation in radius lengths)</li>
<li><code>compactness</code> (perimeter^2 / area - 1.0)</li>
<li><code>concavity</code> (severity of concave portions of the contour)</li>
<li><code>concave</code> points (number of concave portions of the contour)</li>
<li><code>symmetry</code></li>
<li><code>fractal dimension</code> (“coastline approximation” - 1)</li>
</ul></li>
</ul>
<p><code>*_mean</code>: the means of all cells</p>
<p><code>*_se</code>: standard error of all cells</p>
<p><code>*_worst</code>: the worst cell</p>
</section>

<section id="and-now" class="title-slide slide level1 center">
<h1>… and now?</h1>
<p>Take a first glance to the dataset</p>
<ul>
<li>Do we consider all features?</li>
<li>Are there null values?</li>
<li>Which are the attribute types?</li>
<li>Which are the attribute ranges?</li>
<li>How many labels?</li>
<li>Are classes unbalanced?</li>
<li>Check the attribute’s distribution</li>
<li>Check the relationships between attributes (e.g., the correlation). Should we keep all attributes?</li>
</ul>
</section>

<section id="data-distribution" class="title-slide slide level1 center">
<h1>Data distribution</h1>
<div id="cell-12" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:06:44.942686Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:06:44.942527Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:06:44.986726Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:06:44.986086Z&quot;}" data-execution_count="5">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb5-1"><a href=""></a>df.describe()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="5">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">radius_mean</th>
<th data-quarto-table-cell-role="th">texture_mean</th>
<th data-quarto-table-cell-role="th">perimeter_mean</th>
<th data-quarto-table-cell-role="th">area_mean</th>
<th data-quarto-table-cell-role="th">smoothness_mean</th>
<th data-quarto-table-cell-role="th">compactness_mean</th>
<th data-quarto-table-cell-role="th">concavity_mean</th>
<th data-quarto-table-cell-role="th">concave points_mean</th>
<th data-quarto-table-cell-role="th">symmetry_mean</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">texture_worst</th>
<th data-quarto-table-cell-role="th">perimeter_worst</th>
<th data-quarto-table-cell-role="th">area_worst</th>
<th data-quarto-table-cell-role="th">smoothness_worst</th>
<th data-quarto-table-cell-role="th">compactness_worst</th>
<th data-quarto-table-cell-role="th">concavity_worst</th>
<th data-quarto-table-cell-role="th">concave points_worst</th>
<th data-quarto-table-cell-role="th">symmetry_worst</th>
<th data-quarto-table-cell-role="th">fractal_dimension_worst</th>
<th data-quarto-table-cell-role="th">Unnamed: 32</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>5.690000e+02</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>...</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean</td>
<td>3.037183e+07</td>
<td>14.127292</td>
<td>19.289649</td>
<td>91.969033</td>
<td>654.889104</td>
<td>0.096360</td>
<td>0.104341</td>
<td>0.088799</td>
<td>0.048919</td>
<td>0.181162</td>
<td>...</td>
<td>25.677223</td>
<td>107.261213</td>
<td>880.583128</td>
<td>0.132369</td>
<td>0.254265</td>
<td>0.272188</td>
<td>0.114606</td>
<td>0.290076</td>
<td>0.083946</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std</td>
<td>1.250206e+08</td>
<td>3.524049</td>
<td>4.301036</td>
<td>24.298981</td>
<td>351.914129</td>
<td>0.014064</td>
<td>0.052813</td>
<td>0.079720</td>
<td>0.038803</td>
<td>0.027414</td>
<td>...</td>
<td>6.146258</td>
<td>33.602542</td>
<td>569.356993</td>
<td>0.022832</td>
<td>0.157336</td>
<td>0.208624</td>
<td>0.065732</td>
<td>0.061867</td>
<td>0.018061</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">min</td>
<td>8.670000e+03</td>
<td>6.981000</td>
<td>9.710000</td>
<td>43.790000</td>
<td>143.500000</td>
<td>0.052630</td>
<td>0.019380</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.106000</td>
<td>...</td>
<td>12.020000</td>
<td>50.410000</td>
<td>185.200000</td>
<td>0.071170</td>
<td>0.027290</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.156500</td>
<td>0.055040</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">25%</td>
<td>8.692180e+05</td>
<td>11.700000</td>
<td>16.170000</td>
<td>75.170000</td>
<td>420.300000</td>
<td>0.086370</td>
<td>0.064920</td>
<td>0.029560</td>
<td>0.020310</td>
<td>0.161900</td>
<td>...</td>
<td>21.080000</td>
<td>84.110000</td>
<td>515.300000</td>
<td>0.116600</td>
<td>0.147200</td>
<td>0.114500</td>
<td>0.064930</td>
<td>0.250400</td>
<td>0.071460</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50%</td>
<td>9.060240e+05</td>
<td>13.370000</td>
<td>18.840000</td>
<td>86.240000</td>
<td>551.100000</td>
<td>0.095870</td>
<td>0.092630</td>
<td>0.061540</td>
<td>0.033500</td>
<td>0.179200</td>
<td>...</td>
<td>25.410000</td>
<td>97.660000</td>
<td>686.500000</td>
<td>0.131300</td>
<td>0.211900</td>
<td>0.226700</td>
<td>0.099930</td>
<td>0.282200</td>
<td>0.080040</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75%</td>
<td>8.813129e+06</td>
<td>15.780000</td>
<td>21.800000</td>
<td>104.100000</td>
<td>782.700000</td>
<td>0.105300</td>
<td>0.130400</td>
<td>0.130700</td>
<td>0.074000</td>
<td>0.195700</td>
<td>...</td>
<td>29.720000</td>
<td>125.400000</td>
<td>1084.000000</td>
<td>0.146000</td>
<td>0.339100</td>
<td>0.382900</td>
<td>0.161400</td>
<td>0.317900</td>
<td>0.092080</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">max</td>
<td>9.113205e+08</td>
<td>28.110000</td>
<td>39.280000</td>
<td>188.500000</td>
<td>2501.000000</td>
<td>0.163400</td>
<td>0.345400</td>
<td>0.426800</td>
<td>0.201200</td>
<td>0.304000</td>
<td>...</td>
<td>49.540000</td>
<td>251.200000</td>
<td>4254.000000</td>
<td>0.222600</td>
<td>1.058000</td>
<td>1.252000</td>
<td>0.291000</td>
<td>0.663800</td>
<td>0.207500</td>
<td>NaN</td>
</tr>
</tbody>
</table>

<p>8 rows × 32 columns</p>
</div>
</div>
</div>
</section>

<section id="diagnosis" class="title-slide slide level1 center">
<h1><code>diagnosis</code></h1>
<div id="cell-14" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:06:44.988594Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:06:44.988426Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:06:44.992816Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:06:44.992263Z&quot;}" data-execution_count="6">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb6-1"><a href=""></a>df[<span class="st">'diagnosis'</span>].value_counts()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>diagnosis
B    357
M    212
Name: count, dtype: int64</code></pre>
</div>
</div>
<div id="cell-15" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:06:44.994753Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:06:44.994355Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:06:45.093661Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:06:45.093056Z&quot;}" data-execution_count="7">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb8-1"><a href=""></a>sns.countplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">'diagnosis'</span>, hue<span class="op">=</span><span class="st">'diagnosis'</span>)</span></code></pre></div>
</details>

</div>
<img data-src="lab-09-breastcancer.solution_files/figure-revealjs/cell-8-output-1.png" class="r-stretch"></section>

<section id="summing-up" class="title-slide slide level1 center">
<h1>Summing up</h1>
<table>
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Question</th>
<th>Answer</th>
<th>Do we need action?</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Are there null values?</td>
<td>Yes</td>
<td>No need for imputation, drop the column</td>
</tr>
<tr class="even">
<td>Which are the attribute types?</td>
<td>All attributes are numeric but <code>diagnosis</code></td>
<td>Encode diagnosis</td>
</tr>
<tr class="odd">
<td>Which are the attribute ranges?</td>
<td>Attribute ranges are similar</td>
<td>We could apply normalization</td>
</tr>
<tr class="even">
<td>How many labels?</td>
<td>2</td>
<td>-</td>
</tr>
<tr class="odd">
<td>Are classes unbalanced?</td>
<td>No, classess are almost equally distributed</td>
<td>No rebalancing</td>
</tr>
</tbody>
</table>
</section>

<section id="data-preprocessing-drop-the-unnecessary-columns" class="title-slide slide level1 center">
<h1>Data preprocessing: Drop the unnecessary columns</h1>
<div id="cell-21" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:07:45.178370Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:07:45.178073Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:07:45.181245Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:07:45.180779Z&quot;}" data-execution_count="11">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb9-1"><a href=""></a><span class="co"># `Unnamed:32` has 0 non null objects, all values are null. Drop the column</span></span>
<span id="cb9-2"><a href=""></a>df.drop([<span class="st">"id"</span>, <span class="st">"Unnamed: 32"</span>], axis<span class="op">=</span><span class="dv">1</span>, inplace<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
</details>
</div>
</section>

<section id="data-preprocessing-encoding" class="title-slide slide level1 center">
<h1>Data preprocessing: Encoding</h1>
<div id="cell-23" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:07:45.182983Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:07:45.182656Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:07:45.185700Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:07:45.185265Z&quot;}" data-execution_count="12">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb10-1"><a href=""></a><span class="co"># map the diagnosis column to numeric</span></span>
<span id="cb10-2"><a href=""></a>df[<span class="st">'diagnosis'</span>] <span class="op">=</span> df[<span class="st">'diagnosis'</span>].<span class="bu">map</span>({<span class="st">'M'</span>: <span class="dv">1</span>, <span class="st">'B'</span>: <span class="dv">0</span>})</span></code></pre></div>
</details>
</div>
</section>

<section id="data-visualization" class="title-slide slide level1 center">
<h1>Data visualization</h1>
<p>For now, let’s just focus on <code>*_mean</code> attributes</p>
<div id="cell-25" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:07:45.187422Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:07:45.187013Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:07:45.190785Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:07:45.190207Z&quot;}" data-execution_count="13">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb11-1"><a href=""></a>features_mean <span class="op">=</span> <span class="bu">list</span>(df.columns[<span class="dv">1</span>:<span class="dv">11</span>]) <span class="op">+</span> [<span class="st">"diagnosis"</span>]</span>
<span id="cb11-2"><a href=""></a>features_se <span class="op">=</span> <span class="bu">list</span>(df.columns[<span class="dv">11</span>:<span class="dv">20</span>]) <span class="op">+</span> [<span class="st">"diagnosis"</span>]</span>
<span id="cb11-3"><a href=""></a>features_worst <span class="op">=</span> <span class="bu">list</span>(df.columns[<span class="dv">21</span>:<span class="dv">31</span>]) <span class="op">+</span> [<span class="st">"diagnosis"</span>]</span>
<span id="cb11-4"><a href=""></a><span class="bu">print</span>(<span class="st">"features_mean: "</span> <span class="op">+</span> <span class="bu">str</span>(features_mean))</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>features_mean: ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'diagnosis']</code></pre>
</div>
</div>
<div id="cell-26" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:07:45.192481Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:07:45.192179Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:07:46.396989Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:07:46.396402Z&quot;}" data-execution_count="14">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb13-1"><a href=""></a>df[features_mean].hist(bins<span class="op">=</span><span class="dv">50</span>, figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">15</span>))</span>
<span id="cb13-2"><a href=""></a>plt.show()</span></code></pre></div>
</details>

</div>
<img data-src="lab-09-breastcancer.solution_files/figure-revealjs/cell-15-output-1.png" class="r-stretch"></section>

<section id="checking-correlations" class="title-slide slide level1 center">
<h1>Checking correlations</h1>
<div id="cell-28" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:07:46.398979Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:07:46.398623Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:01.488020Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:01.487376Z&quot;}" data-execution_count="15">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb14-1"><a href=""></a>sns.pairplot(df[features_mean], hue<span class="op">=</span><span class="st">'diagnosis'</span>, markers<span class="op">=</span><span class="st">'+'</span>)</span>
<span id="cb14-2"><a href=""></a>plt.show()</span></code></pre></div>
</details>

</div>
<img data-src="lab-09-breastcancer.solution_files/figure-revealjs/cell-16-output-1.png" class="r-stretch"></section>

<section id="section" class="title-slide slide level1 center">
<h1></h1>
<div id="cell-31" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:01.555084Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:01.554742Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:01.892245Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:01.891634Z&quot;}" data-execution_count="17">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb15-1"><a href=""></a>min_corr <span class="op">=</span> <span class="fl">0.3</span></span>
<span id="cb15-2"><a href=""></a>kot <span class="op">=</span> rho[(<span class="bu">abs</span>(rho) <span class="op">&gt;=</span> min_corr) <span class="op">&amp;</span> (rho <span class="op">&lt;</span> <span class="dv">1</span>)]</span>
<span id="cb15-3"><a href=""></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">14</span>))</span>
<span id="cb15-4"><a href=""></a>sns.heatmap(kot, cmap<span class="op">=</span>sns.color_palette(<span class="st">"coolwarm"</span>, as_cmap<span class="op">=</span><span class="va">True</span>), annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span> <span class="st">'.2f'</span>,annot_kws<span class="op">=</span>{<span class="st">'size'</span>: <span class="dv">15</span>})</span></code></pre></div>
</details>

</div>
<img data-src="lab-09-breastcancer.solution_files/figure-revealjs/cell-18-output-1.png" class="r-stretch"></section>

<section id="should-we-drop-some-attributes" class="title-slide slide level1 center">
<h1>Should we drop some attributes?</h1>
<ul>
<li><code>radius_mean</code>, <code>perimeter_mean</code>, and <code>area_mean</code> are highly correlated, keep <code>perimeter</code></li>
<li><code>compactness_mean</code>, <code>concavity_mean</code> and <code>concavepoint_mean</code> are highly correlated, keep <code>compactness_mean</code></li>
</ul>
<div id="cell-33" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:01.894041Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:01.893873Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:01.896619Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:01.896183Z&quot;}" data-execution_count="18">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb16-1"><a href=""></a><span class="co"># now these are the variables that we will use for prediction</span></span>
<span id="cb16-2"><a href=""></a>prediction_var <span class="op">=</span> [<span class="st">'texture_mean'</span>, <span class="st">'perimeter_mean'</span>, <span class="st">'smoothness_mean'</span>, <span class="st">'compactness_mean'</span>, <span class="st">'symmetry_mean'</span>]</span></code></pre></div>
</details>
</div>
</section>

<section id="modeling-with-scikit-learn" class="title-slide slide level1 center">
<h1>Modeling with scikit-learn</h1>
<p>Preparing the datasets for the ML pipeline.</p>
<ul>
<li>X: the dataset</li>
<li>y: the labels</li>
</ul>
<div id="cell-35" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:01.898519Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:01.898214Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:01.904455Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:01.903898Z&quot;}" data-execution_count="19">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb17-1"><a href=""></a><span class="kw">def</span> set_dataset(feature_list, normalize<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb17-2"><a href=""></a>    X <span class="op">=</span> df[feature_list <span class="op">+</span> [<span class="st">'diagnosis'</span>]].drop(<span class="st">'diagnosis'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb17-3"><a href=""></a>    y <span class="op">=</span> df[<span class="st">'diagnosis'</span>]</span>
<span id="cb17-4"><a href=""></a>    <span class="cf">if</span> normalize: X <span class="op">=</span> (X <span class="op">-</span> X.mean()) <span class="op">/</span> X.std()</span>
<span id="cb17-5"><a href=""></a>    <span class="bu">print</span>(<span class="ss">f"X.shape: </span><span class="sc">{</span>X<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, y.shape: </span><span class="sc">{</span>y<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-6"><a href=""></a>    <span class="cf">return</span> X, y</span>
<span id="cb17-7"><a href=""></a></span>
<span id="cb17-8"><a href=""></a>X, y <span class="op">=</span> set_dataset(prediction_var, <span class="va">True</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>X.shape: (569, 5), y.shape: (569,)</code></pre>
</div>
</div>
</section>

<section id="splitting-the-datasets-into-a-training-set-and-a-testing-set" class="title-slide slide level1 center">
<h1>Splitting the datasets into a training set and a testing set</h1>
<p>Advantages</p>
<ul>
<li>By splitting the dataset pseudo-randomly into a two separate sets, we can train using one set and test using another.</li>
<li>This ensures that we won’t use the same observations in both sets.</li>
</ul>
<p>Disadvantages</p>
<ul>
<li>The accuracy scores for the testing set can vary depending on what observations are in the set.</li>
<li>This disadvantage can be countered using k-fold cross-validation.</li>
</ul>
<p>Notes</p>
<ul>
<li>The accuracy score of the models depends on the observations in the testing set, which is determined by the seed of the pseudo-random number generator (random_state parameter).</li>
<li>As a model’s complexity increases, the training accuracy increases.</li>
<li>If a model is too complex or not complex enough, the testing accuracy is lower.
<ul>
<li>E.g., K-NN models, the value of k determines the level of complexity.</li>
</ul></li>
</ul>
<div id="cell-37" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:01.906030Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:01.905870Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:01.909761Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:01.909311Z&quot;}" data-execution_count="20">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb19-1"><a href=""></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb19-2"><a href=""></a><span class="bu">print</span>(<span class="ss">f"y_train.shape: </span><span class="sc">{</span>X<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, y_train.shape: </span><span class="sc">{</span>y_train<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>y_train.shape: (569, 5), y_train.shape: (398,)</code></pre>
</div>
</div>
</section>

<section id="visualizing-the-data-how" class="title-slide slide level1 center">
<h1>Visualizing the data… how?</h1>

</section>

<section id="visualizing-the-data-in-3d" class="title-slide slide level1 center">
<h1>Visualizing the data in 3D</h1>
<div id="cell-40" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:01.911427Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:01.911263Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:02.024570Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:02.024031Z&quot;}" data-execution_count="21">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb21-1"><a href=""></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb21-2"><a href=""></a></span>
<span id="cb21-3"><a href=""></a>fig <span class="op">=</span> plt.figure()</span>
<span id="cb21-4"><a href=""></a>ax <span class="op">=</span> fig.add_subplot(projection<span class="op">=</span><span class="st">'3d'</span>)</span>
<span id="cb21-5"><a href=""></a></span>
<span id="cb21-6"><a href=""></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb21-7"><a href=""></a>result <span class="op">=</span> pca.fit_transform(X_train)</span>
<span id="cb21-8"><a href=""></a></span>
<span id="cb21-9"><a href=""></a>ax.scatter(</span>
<span id="cb21-10"><a href=""></a>    xs<span class="op">=</span>result[:,<span class="dv">0</span>],</span>
<span id="cb21-11"><a href=""></a>    ys<span class="op">=</span>result[:,<span class="dv">1</span>],</span>
<span id="cb21-12"><a href=""></a>    zs<span class="op">=</span>result[:,<span class="dv">2</span>],</span>
<span id="cb21-13"><a href=""></a>    c<span class="op">=</span>y_train,</span>
<span id="cb21-14"><a href=""></a>    cmap<span class="op">=</span><span class="st">'viridis'</span></span>
<span id="cb21-15"><a href=""></a>)</span></code></pre></div>
</details>

</div>
<img data-src="lab-09-breastcancer.solution_files/figure-revealjs/cell-22-output-1.png" class="r-stretch"></section>

<section id="visualizing-the-data-in-2d" class="title-slide slide level1 center">
<h1>Visualizing the data in 2D</h1>
<div id="cell-42" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:02.026324Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:02.026155Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:02.125197Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:02.124571Z&quot;}" data-execution_count="22">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb22-1"><a href=""></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb22-2"><a href=""></a>result <span class="op">=</span> pca.fit_transform(X_train)</span>
<span id="cb22-3"><a href=""></a></span>
<span id="cb22-4"><a href=""></a>plt.scatter(</span>
<span id="cb22-5"><a href=""></a>    x<span class="op">=</span>result[:,<span class="dv">0</span>],</span>
<span id="cb22-6"><a href=""></a>    y<span class="op">=</span>result[:,<span class="dv">1</span>] ,</span>
<span id="cb22-7"><a href=""></a>    c<span class="op">=</span>y_train,</span>
<span id="cb22-8"><a href=""></a>    cmap<span class="op">=</span><span class="st">'viridis'</span></span>
<span id="cb22-9"><a href=""></a>)</span></code></pre></div>
</details>

</div>
<img data-src="lab-09-breastcancer.solution_files/figure-revealjs/cell-23-output-1.png" class="r-stretch"></section>

<section id="outlier-detection" class="title-slide slide level1 center">
<h1>Outlier detection</h1>
<div id="cell-44" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:02.127084Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:02.126746Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:02.323571Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:02.323073Z&quot;}" data-execution_count="23">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb23-1"><a href=""></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> IsolationForest</span>
<span id="cb23-2"><a href=""></a>clf <span class="op">=</span> IsolationForest()</span>
<span id="cb23-3"><a href=""></a>clf.fit(X_train)</span>
<span id="cb23-4"><a href=""></a>is_outlier <span class="op">=</span> clf.predict(X_train)</span>
<span id="cb23-5"><a href=""></a></span>
<span id="cb23-6"><a href=""></a>plt.scatter(</span>
<span id="cb23-7"><a href=""></a>    x<span class="op">=</span>result[:,<span class="dv">0</span>],</span>
<span id="cb23-8"><a href=""></a>    y<span class="op">=</span>result[:,<span class="dv">1</span>],</span>
<span id="cb23-9"><a href=""></a>    s<span class="op">=</span>[<span class="dv">10</span> <span class="cf">if</span> x <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">20</span> <span class="cf">for</span> x <span class="kw">in</span> is_outlier],</span>
<span id="cb23-10"><a href=""></a>    c<span class="op">=</span>is_outlier,</span>
<span id="cb23-11"><a href=""></a>    cmap<span class="op">=</span><span class="st">'viridis'</span></span>
<span id="cb23-12"><a href=""></a>)</span></code></pre></div>
</details>

</div>
<img data-src="lab-09-breastcancer.solution_files/figure-revealjs/cell-24-output-1.png" class="r-stretch"></section>

<section id="logistic-regression" class="title-slide slide level1 center">
<h1>Logistic regression</h1>
<div id="cell-46" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:02.325470Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:02.325281Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:02.334031Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:02.333586Z&quot;}" data-execution_count="24">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb24-1"><a href=""></a><span class="co"># all parameters not specified are set to their defaults</span></span>
<span id="cb24-2"><a href=""></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb24-3"><a href=""></a></span>
<span id="cb24-4"><a href=""></a>logisticRegr <span class="op">=</span> LogisticRegression(random_state<span class="op">=</span>seed)</span>
<span id="cb24-5"><a href=""></a>logisticRegr.fit(X_train, y_train)</span>
<span id="cb24-6"><a href=""></a>y_pred <span class="op">=</span> logisticRegr.predict(X_test)</span>
<span id="cb24-7"><a href=""></a>metrics.accuracy_score(y_test, y_pred)</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>0.9122807017543859</code></pre>
</div>
</div>
</section>

<section id="k-nearest-neighbors" class="title-slide slide level1 center">
<h1>k-Nearest Neighbors</h1>
<div id="cell-48" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:02.335751Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:02.335424Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:02.966652Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:02.966182Z&quot;}" data-execution_count="25">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb26-1"><a href=""></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb26-2"><a href=""></a><span class="kw">def</span> fit_knn(X_train, y_train, X_test, y_test):</span>
<span id="cb26-3"><a href=""></a>    k_range <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">30</span>))</span>
<span id="cb26-4"><a href=""></a>    scores <span class="op">=</span> []</span>
<span id="cb26-5"><a href=""></a>    conf_matrix <span class="op">=</span> <span class="va">None</span></span>
<span id="cb26-6"><a href=""></a>    <span class="cf">for</span> k <span class="kw">in</span> k_range:</span>
<span id="cb26-7"><a href=""></a>        knn <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span>k)</span>
<span id="cb26-8"><a href=""></a>        knn.fit(X_train, y_train)</span>
<span id="cb26-9"><a href=""></a>        y_pred <span class="op">=</span> knn.predict(X_test)</span>
<span id="cb26-10"><a href=""></a>        scores.append(metrics.accuracy_score(y_test, y_pred))</span>
<span id="cb26-11"><a href=""></a>        <span class="cf">if</span> k <span class="op">==</span> <span class="dv">1</span>: conf_matrix <span class="op">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb26-12"><a href=""></a>    fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="fl">2.5</span>))</span>
<span id="cb26-13"><a href=""></a>    <span class="cf">if</span> conf_matrix <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb26-14"><a href=""></a>        sns.heatmap(conf_matrix, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">"d"</span>, cmap<span class="op">=</span><span class="st">"Blues"</span>, cbar<span class="op">=</span><span class="va">False</span>, ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb26-15"><a href=""></a>        axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Predicted labels'</span>)</span>
<span id="cb26-16"><a href=""></a>        axes[<span class="dv">0</span>].set_ylabel(<span class="st">'True labels'</span>)</span>
<span id="cb26-17"><a href=""></a>        axes[<span class="dv">0</span>].set_title(<span class="st">'Confusion Matrix (k=1)'</span>)</span>
<span id="cb26-18"><a href=""></a>    axes[<span class="dv">1</span>].plot(k_range, scores, marker<span class="op">=</span><span class="st">'o'</span>, linestyle<span class="op">=</span><span class="st">'-'</span>, color<span class="op">=</span><span class="st">'b'</span>)</span>
<span id="cb26-19"><a href=""></a>    axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Value of k for KNN'</span>)</span>
<span id="cb26-20"><a href=""></a>    axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Accuracy Score'</span>)</span>
<span id="cb26-21"><a href=""></a>    axes[<span class="dv">1</span>].grid(<span class="va">True</span>)</span>
<span id="cb26-22"><a href=""></a>    fig.tight_layout()</span>
<span id="cb26-23"><a href=""></a>    <span class="cf">return</span> y_pred</span>
<span id="cb26-24"><a href=""></a>p <span class="op">=</span> fit_knn(X_train, y_train, X_test, y_test)</span></code></pre></div>
</details>

</div>
<img data-src="lab-09-breastcancer.solution_files/figure-revealjs/cell-26-output-1.png" class="r-stretch"></section>

<section id="train-vs-train" class="title-slide slide level1 center">
<h1>Train vs train</h1>
<p>What if I compare the model vs the model trained on the training set only?</p>
<div id="cell-50" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:02.968332Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:02.968164Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:03.596727Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:03.596142Z&quot;}" data-execution_count="26">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb27-1"><a href=""></a>p <span class="op">=</span> fit_knn(X_train, y_train, X_train, y_train)</span></code></pre></div>
</details>

</div>
<img data-src="lab-09-breastcancer.solution_files/figure-revealjs/cell-27-output-1.png" class="r-stretch"></section>

<section id="what-if-i-choose-a-more-complex-model" class="title-slide slide level1 center">
<h1>What if I choose a more complex model?</h1>
<div id="cell-52" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:03.598723Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:03.598366Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:03.720201Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:03.719722Z&quot;}" data-execution_count="27">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb28-1"><a href=""></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb28-2"><a href=""></a></span>
<span id="cb28-3"><a href=""></a><span class="kw">def</span> fit_forest(X_train, y_train, X_test, y_test):</span>
<span id="cb28-4"><a href=""></a>    model<span class="op">=</span>RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span>seed) <span class="co"># a simple random forest model</span></span>
<span id="cb28-5"><a href=""></a>    model.fit(X_train, y_train) <span class="co"># now fit our model for training data</span></span>
<span id="cb28-6"><a href=""></a>    y_pred <span class="op">=</span> model.predict(X_test) <span class="co"># predict for the test data</span></span>
<span id="cb28-7"><a href=""></a>    <span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>metrics<span class="sc">.</span>accuracy_score(y_pred, y_test)<span class="sc">}</span><span class="ss">"</span>) <span class="co"># to check the accuracy</span></span>
<span id="cb28-8"><a href=""></a>    featimp <span class="op">=</span> pd.Series(model.feature_importances_, index<span class="op">=</span>X_train.columns).sort_values(ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb28-9"><a href=""></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Features sorted by descending importance:"</span>)</span>
<span id="cb28-10"><a href=""></a>    <span class="bu">print</span>(featimp) <span class="co"># this is the property of Random Forest classifier that it provide us the importance of the features used</span></span>
<span id="cb28-11"><a href=""></a></span>
<span id="cb28-12"><a href=""></a>fit_forest(X_train, y_train, X_test, y_test)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.9181286549707602

Features sorted by descending importance:
perimeter_mean      0.500370
compactness_mean    0.208219
texture_mean        0.152675
smoothness_mean     0.084973
symmetry_mean       0.053763
dtype: float64</code></pre>
</div>
</div>
</section>

<section id="section-1" class="title-slide slide level1 center">
<h1></h1>
<p>Now lets do this for all <code>feature_mean</code> so that from Random forest we can get the feature which are important</p>
<div id="cell-54" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:03.722167Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:03.721801Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:03.850497Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:03.849975Z&quot;}" data-execution_count="28">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb30-1"><a href=""></a>X, y <span class="op">=</span> set_dataset(features_mean, <span class="va">True</span>) <span class="co"># taking all features</span></span>
<span id="cb30-2"><a href=""></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb30-3"><a href=""></a>fit_forest(X_train, y_train, X_test, y_test)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>X.shape: (569, 10), y.shape: (569,)
Accuracy: 0.9473684210526315

Features sorted by descending importance:
concave points_mean       0.299529
perimeter_mean            0.162114
concavity_mean            0.144159
area_mean                 0.112537
radius_mean               0.096991
texture_mean              0.071964
compactness_mean          0.042297
smoothness_mean           0.029874
symmetry_mean             0.023971
fractal_dimension_mean    0.016563
dtype: float64</code></pre>
</div>
</div>
</section>

<section id="cross-validation" class="title-slide slide level1 center">
<h1><a href="https://scikit-learn.org/stable/modules/cross_validation.html">Cross-validation</a></h1>
<div id="cell-56" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:03.852329Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:03.851958Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:04.487584Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:04.486958Z&quot;}" data-execution_count="29">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb32-1"><a href=""></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score</span>
<span id="cb32-2"><a href=""></a></span>
<span id="cb32-3"><a href=""></a><span class="kw">def</span> cv(model, X, y):</span>
<span id="cb32-4"><a href=""></a>    scores <span class="op">=</span> cross_val_score(model, X, y, cv<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb32-5"><a href=""></a>    <span class="bu">print</span>(<span class="st">"Scores: "</span> <span class="op">+</span> <span class="bu">str</span>(scores))</span>
<span id="cb32-6"><a href=""></a>    <span class="bu">print</span>(<span class="st">"</span><span class="sc">%0.3f</span><span class="st"> accuracy with a standard deviation of </span><span class="sc">%0.2f</span><span class="st">"</span> <span class="op">%</span> (scores.mean(), scores.std()))</span>
<span id="cb32-7"><a href=""></a></span>
<span id="cb32-8"><a href=""></a>cv(RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span>seed), X, y)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Scores: [0.90350877 0.93859649 0.92105263 0.97368421 0.95575221]
0.939 accuracy with a standard deviation of 0.02</code></pre>
</div>
</div>
<div id="cell-57" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:04.489554Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:04.489220Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:04.533625Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:04.533030Z&quot;}" data-execution_count="30">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb34-1"><a href=""></a>cv(KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">10</span>), X, y)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Scores: [0.92105263 0.94736842 0.94736842 0.97368421 0.92035398]
0.942 accuracy with a standard deviation of 0.02</code></pre>
</div>
</div>
</section>

<section id="hyperparameter-optimization" class="title-slide slide level1 center">
<h1>Hyperparameter optimization</h1>
<div id="cell-59" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:04.535713Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:04.535273Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:04.538708Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:04.538153Z&quot;}" data-execution_count="31">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb36-1"><a href=""></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb36-2"><a href=""></a></span>
<span id="cb36-3"><a href=""></a><span class="kw">def</span> gridsearch_cv(model,param_grid, X_train, y_train):</span>
<span id="cb36-4"><a href=""></a>    clf <span class="op">=</span> GridSearchCV(model, param_grid, cv<span class="op">=</span><span class="dv">5</span>, scoring<span class="op">=</span><span class="st">"accuracy"</span>, verbose<span class="op">=</span><span class="dv">1</span>, n_jobs<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb36-5"><a href=""></a>    clf.fit(X_train, y_train)</span>
<span id="cb36-6"><a href=""></a>    <span class="bu">print</span>(<span class="ss">f"The best score is </span><span class="sc">{</span>clf<span class="sc">.</span>best_score_<span class="sc">}</span><span class="ss">, with parameters </span><span class="sc">{</span>clf<span class="sc">.</span>best_params_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb36-7"><a href=""></a>    <span class="cf">return</span> clf.best_estimator_</span></code></pre></div>
</details>
</div>
<div id="cell-60" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:04.540548Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:04.540281Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:07.625608Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:07.624990Z&quot;}" data-execution_count="32">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb37-1"><a href=""></a>param_grid <span class="op">=</span> {</span>
<span id="cb37-2"><a href=""></a>    <span class="st">'n_neighbors'</span>: <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">30</span>, <span class="dv">3</span>)),</span>
<span id="cb37-3"><a href=""></a>    <span class="st">'leaf_size'</span>: <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">30</span>, <span class="dv">3</span>))</span>
<span id="cb37-4"><a href=""></a>}</span>
<span id="cb37-5"><a href=""></a>gridsearch_cv(KNeighborsClassifier(), param_grid, X, y)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 5 folds for each of 100 candidates, totalling 500 fits
The best score is 0.9455364073901567, with parameters {'leaf_size': 1, 'n_neighbors': 16}</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="32">
<style>#sk-container-id-2 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-2 {
  color: var(--sklearn-color-text);
}

#sk-container-id-2 pre {
  padding: 0;
}

#sk-container-id-2 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-2 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-2 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-2 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-2 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-2 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-2 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-2 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-2 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-2 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-2 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-2 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-2 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-2 div.sk-label label.sk-toggleable__label,
#sk-container-id-2 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-2 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-2 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-2 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-2 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-2 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-2 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-2 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-2 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>KNeighborsClassifier(leaf_size=1, n_neighbors=16)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked=""><label for="sk-estimator-id-2" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;KNeighborsClassifier<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.KNeighborsClassifier.html">?<span>Documentation for KNeighborsClassifier</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>KNeighborsClassifier(leaf_size=1, n_neighbors=16)</pre></div> </div></div></div></div>
</div>
</div>
<div id="cell-61" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:07.627702Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:07.627512Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:08.283069Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:08.282529Z&quot;}" data-execution_count="33">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb39-1"><a href=""></a>param_grid <span class="op">=</span> {</span>
<span id="cb39-2"><a href=""></a>    <span class="st">'n_estimators'</span>: [<span class="dv">10</span>, <span class="dv">50</span>, <span class="dv">100</span>],</span>
<span id="cb39-3"><a href=""></a>    <span class="st">"random_state"</span>: [seed]</span>
<span id="cb39-4"><a href=""></a>}</span>
<span id="cb39-5"><a href=""></a>clf <span class="op">=</span> gridsearch_cv(RandomForestClassifier(), param_grid, X, y)</span>
<span id="cb39-6"><a href=""></a>clf</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 5 folds for each of 3 candidates, totalling 15 fits
The best score is 0.9385188635305077, with parameters {'n_estimators': 50, 'random_state': 42}</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="33">
<style>#sk-container-id-3 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-3 {
  color: var(--sklearn-color-text);
}

#sk-container-id-3 pre {
  padding: 0;
}

#sk-container-id-3 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-3 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-3 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-3 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-3 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-3 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-3 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-3 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-3 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-3 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-3 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-3 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-3 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-3 div.sk-label label.sk-toggleable__label,
#sk-container-id-3 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-3 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-3 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-3 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-3 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-3 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-3 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-3 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-3 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>RandomForestClassifier(n_estimators=50, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" checked=""><label for="sk-estimator-id-3" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;RandomForestClassifier<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html">?<span>Documentation for RandomForestClassifier</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>RandomForestClassifier(n_estimators=50, random_state=42)</pre></div> </div></div></div></div>
</div>
</div>
</section>

<section id="feature-selection" class="title-slide slide level1 center">
<h1>Feature selection</h1>
<div id="cell-63" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:08.284897Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:08.284712Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:10.304265Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:10.303635Z&quot;}" data-execution_count="34">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb41-1"><a href=""></a><span class="im">from</span> sklearn.feature_selection <span class="im">import</span> RFECV</span>
<span id="cb41-2"><a href=""></a>rfecv <span class="op">=</span> RFECV(estimator<span class="op">=</span>clf, step<span class="op">=</span><span class="dv">1</span>, cv<span class="op">=</span><span class="dv">5</span>, scoring<span class="op">=</span><span class="st">"accuracy"</span>, min_features_to_select<span class="op">=</span><span class="dv">1</span>, n_jobs<span class="op">=</span><span class="dv">2</span>, verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb41-3"><a href=""></a>rfecv.fit(X, y)</span>
<span id="cb41-4"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Optimal number of features: </span><span class="sc">{</span>rfecv<span class="sc">.</span>n_features_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb41-5"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Feature ranking: </span><span class="sc">{</span>rfecv<span class="sc">.</span>ranking_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb41-6"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Selected features: </span><span class="sc">{</span><span class="bu">list</span>(X.columns[rfecv.support_])<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting estimator with 10 features.
Optimal number of features: 9
Feature ranking: [1 1 1 1 1 1 1 1 2 1]
Selected features: ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'fractal_dimension_mean']</code></pre>
</div>
</div>
<div id="cell-64" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:10.306255Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:10.305805Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:10.392943Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:10.392370Z&quot;}" data-execution_count="35">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb43-1"><a href=""></a>cv_results <span class="op">=</span> pd.DataFrame(rfecv.cv_results_)</span>
<span id="cb43-2"><a href=""></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">3</span>, <span class="fl">2.5</span>))</span>
<span id="cb43-3"><a href=""></a>plt.xlabel(<span class="st">"Number of features selected"</span>)</span>
<span id="cb43-4"><a href=""></a>plt.ylabel(<span class="st">"Mean test accuracy"</span>)</span>
<span id="cb43-5"><a href=""></a>plt.errorbar(x<span class="op">=</span>cv_results[<span class="st">"n_features"</span>], y<span class="op">=</span>cv_results[<span class="st">"mean_test_score"</span>], yerr<span class="op">=</span>cv_results[<span class="st">"std_test_score"</span>],)</span>
<span id="cb43-6"><a href=""></a>plt.title(<span class="st">"Recursive Feature Elimination"</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>Text(0.5, 1.0, 'Recursive Feature Elimination')</code></pre>
</div>

</div>
<img data-src="lab-09-breastcancer.solution_files/figure-revealjs/cell-36-output-2.png" class="r-stretch"></section>

<section id="section-2" class="title-slide slide level1 center">
<h1></h1>
<div id="cell-66" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:10.394860Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:10.394537Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:10.726149Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:10.725555Z&quot;}" data-execution_count="36">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb45-1"><a href=""></a><span class="im">from</span> sklearn.feature_selection <span class="im">import</span> RFE</span>
<span id="cb45-2"><a href=""></a></span>
<span id="cb45-3"><a href=""></a>rfe <span class="op">=</span> RFE(clf, n_features_to_select<span class="op">=</span><span class="dv">6</span>, step<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb45-4"><a href=""></a>rfe <span class="op">=</span> rfe.fit(X, y)</span>
<span id="cb45-5"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Selected features:</span><span class="ch">\n</span><span class="sc">{</span><span class="bu">sorted</span>(X.columns[rfe.support_])<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb45-6"><a href=""></a><span class="bu">print</span>(<span class="ss">f"... vs the features we have manually selected:</span><span class="ch">\n</span><span class="sc">{</span><span class="bu">sorted</span>(prediction_var)<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Selected features:
['area_mean', 'concave points_mean', 'concavity_mean', 'perimeter_mean', 'radius_mean', 'texture_mean']
... vs the features we have manually selected:
['compactness_mean', 'perimeter_mean', 'smoothness_mean', 'symmetry_mean', 'texture_mean']</code></pre>
</div>
</div>
</section>

<section id="scikit-learn-pipelines" class="title-slide slide level1 center">
<h1>Scikit-learn pipelines</h1>
<div id="cell-68" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:10.728022Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:10.727734Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:10.984549Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:10.984037Z&quot;}" data-execution_count="37">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb47-1"><a href=""></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb47-2"><a href=""></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb47-3"><a href=""></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb47-4"><a href=""></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb47-5"><a href=""></a></span>
<span id="cb47-6"><a href=""></a><span class="co"># Create a pipeline with scaling and SVC</span></span>
<span id="cb47-7"><a href=""></a>pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb47-8"><a href=""></a>    (<span class="st">'scaler'</span>, StandardScaler()),  <span class="co"># Step 1: Scale the features</span></span>
<span id="cb47-9"><a href=""></a>    (<span class="st">'svc'</span>, SVC())                 <span class="co"># Step 2: Apply Support Vector Classifier</span></span>
<span id="cb47-10"><a href=""></a>])</span>
<span id="cb47-11"><a href=""></a></span>
<span id="cb47-12"><a href=""></a></span>
<span id="cb47-13"><a href=""></a><span class="co"># Define the parameter grid to search</span></span>
<span id="cb47-14"><a href=""></a>param_grid <span class="op">=</span> {</span>
<span id="cb47-15"><a href=""></a>    <span class="st">'svc__C'</span>: [<span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">10</span>],                   <span class="co"># Different values of C for SVC</span></span>
<span id="cb47-16"><a href=""></a>    <span class="st">'svc__kernel'</span>: [<span class="st">'linear'</span>, <span class="st">'rbf'</span>, <span class="st">'poly'</span>], <span class="co"># Different kernel functions for SVC</span></span>
<span id="cb47-17"><a href=""></a>    <span class="st">'svc__random_state'</span>: [seed]</span>
<span id="cb47-18"><a href=""></a>}</span>
<span id="cb47-19"><a href=""></a></span>
<span id="cb47-20"><a href=""></a><span class="co"># Create a GridSearchCV object with the pipeline and parameter grid</span></span>
<span id="cb47-21"><a href=""></a>grid_search <span class="op">=</span> GridSearchCV(pipeline, param_grid, cv<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb47-22"><a href=""></a></span>
<span id="cb47-23"><a href=""></a>grid_search.fit(X_train, y_train)</span>
<span id="cb47-24"><a href=""></a>best_estimator <span class="op">=</span> grid_search.best_estimator_</span>
<span id="cb47-25"><a href=""></a>y_pred <span class="op">=</span> grid_search.predict(X_test)</span>
<span id="cb47-26"><a href=""></a><span class="bu">print</span>(<span class="ss">f"The best score is </span><span class="sc">{</span>grid_search<span class="sc">.</span>best_score_<span class="sc">}</span><span class="ss">, with parameters </span><span class="sc">{</span>grid_search<span class="sc">.</span>best_params_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb47-27"><a href=""></a>grid_search.best_estimator_</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The best score is 0.9572151898734177, with parameters {'svc__C': 10, 'svc__kernel': 'rbf', 'svc__random_state': 42}</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="37">
<style>#sk-container-id-4 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-4 {
  color: var(--sklearn-color-text);
}

#sk-container-id-4 pre {
  padding: 0;
}

#sk-container-id-4 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-4 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-4 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-4 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-4 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-4 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-4 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-4 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-4 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-4 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-4 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-4 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-4 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-4 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-4 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-4 div.sk-label label.sk-toggleable__label,
#sk-container-id-4 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-4 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-4 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-4 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-4 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-4 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-4 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-4 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-4 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-4" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[('scaler', StandardScaler()),
                ('svc', SVC(C=10, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox"><label for="sk-estimator-id-4" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;Pipeline<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html">?<span>Documentation for Pipeline</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[('scaler', StandardScaler()),
                ('svc', SVC(C=10, random_state=42))])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox"><label for="sk-estimator-id-5" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;StandardScaler<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html">?<span>Documentation for StandardScaler</span></a></label><div class="sk-toggleable__content fitted"><pre>StandardScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-6" type="checkbox"><label for="sk-estimator-id-6" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;SVC<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html">?<span>Documentation for SVC</span></a></label><div class="sk-toggleable__content fitted"><pre>SVC(C=10, random_state=42)</pre></div> </div></div></div></div></div></div>
</div>
</div>
</section>

<section id="automl" class="title-slide slide level1 center">
<h1>AutoML</h1>
<div id="cell-70" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:10.986378Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:10.986208Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:37.242663Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:37.242072Z&quot;}" data-execution_count="38">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb49-1"><a href=""></a><span class="kw">def</span> auto_ml(max_iter<span class="op">=</span><span class="dv">300</span>):</span>
<span id="cb49-2"><a href=""></a>    automl <span class="op">=</span> AutoML()</span>
<span id="cb49-3"><a href=""></a>    settings <span class="op">=</span> {</span>
<span id="cb49-4"><a href=""></a>        <span class="st">"time_budget"</span>: <span class="op">-</span><span class="dv">1</span>,  <span class="co"># in seconds (-1 = unlimited)</span></span>
<span id="cb49-5"><a href=""></a>        <span class="st">"max_iter"</span>: max_iter,  <span class="co"># maximum iterations of the search</span></span>
<span id="cb49-6"><a href=""></a>        <span class="st">"metric"</span>: <span class="st">'accuracy'</span>,</span>
<span id="cb49-7"><a href=""></a>        <span class="st">"task"</span>: <span class="st">'classification'</span>,</span>
<span id="cb49-8"><a href=""></a>        <span class="st">"seed"</span>: seed</span>
<span id="cb49-9"><a href=""></a>    }</span>
<span id="cb49-10"><a href=""></a>    automl.fit(X_train<span class="op">=</span>X_train, y_train<span class="op">=</span>y_train, <span class="op">**</span>settings)  <span class="co"># Search for the best model and hyperparameters</span></span>
<span id="cb49-11"><a href=""></a>    y_pred <span class="op">=</span> automl.predict(X_test)  <span class="co"># Make predictions on the test set</span></span>
<span id="cb49-12"><a href=""></a>    <span class="cf">return</span> automl, y_pred</span>
<span id="cb49-13"><a href=""></a></span>
<span id="cb49-14"><a href=""></a>automl, y_pred <span class="op">=</span> auto_ml(<span class="dv">300</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[flaml.automl.logger: 11-29 15:08:10] {1728} INFO - task = classification
[flaml.automl.logger: 11-29 15:08:10] {1739} INFO - Evaluation method: cv
[flaml.automl.logger: 11-29 15:08:10] {1838} INFO - Minimizing error metric: 1-accuracy
[flaml.automl.logger: 11-29 15:08:11] {1955} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'sgd', 'lrl1']
[flaml.automl.logger: 11-29 15:08:11] {2258} INFO - iteration 0, current learner lgbm
[flaml.automl.logger: 11-29 15:08:11] {2393} INFO - Estimated sufficient time budget=10000s. Estimated necessary time budget=10s.
[flaml.automl.logger: 11-29 15:08:11] {2442} INFO -  at 0.0s,   estimator lgbm's best error=0.1282, best estimator lgbm's best error=0.1282
[flaml.automl.logger: 11-29 15:08:11] {2258} INFO - iteration 1, current learner lgbm
[flaml.automl.logger: 11-29 15:08:11] {2442} INFO -  at 0.1s,   estimator lgbm's best error=0.1282, best estimator lgbm's best error=0.1282
[flaml.automl.logger: 11-29 15:08:11] {2258} INFO - iteration 2, current learner lgbm
[flaml.automl.logger: 11-29 15:08:11] {2442} INFO -  at 0.1s,   estimator lgbm's best error=0.0829, best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:11] {2258} INFO - iteration 3, current learner rf
[flaml.automl.logger: 11-29 15:08:11] {2442} INFO -  at 0.3s,   estimator rf's best error=0.1005,   best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:11] {2258} INFO - iteration 4, current learner lgbm
[flaml.automl.logger: 11-29 15:08:11] {2442} INFO -  at 0.3s,   estimator lgbm's best error=0.0829, best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:11] {2258} INFO - iteration 5, current learner lgbm
[flaml.automl.logger: 11-29 15:08:11] {2442} INFO -  at 0.3s,   estimator lgbm's best error=0.0829, best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:11] {2258} INFO - iteration 6, current learner lgbm
[flaml.automl.logger: 11-29 15:08:11] {2442} INFO -  at 0.3s,   estimator lgbm's best error=0.0829, best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:11] {2258} INFO - iteration 7, current learner lgbm
[flaml.automl.logger: 11-29 15:08:11] {2442} INFO -  at 0.4s,   estimator lgbm's best error=0.0829, best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:11] {2258} INFO - iteration 8, current learner lgbm
[flaml.automl.logger: 11-29 15:08:11] {2442} INFO -  at 0.4s,   estimator lgbm's best error=0.0829, best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:11] {2258} INFO - iteration 9, current learner rf
[flaml.automl.logger: 11-29 15:08:11] {2442} INFO -  at 0.6s,   estimator rf's best error=0.0930,   best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:11] {2258} INFO - iteration 10, current learner xgboost
[flaml.automl.logger: 11-29 15:08:11] {2442} INFO -  at 0.6s,   estimator xgboost's best error=0.1080,  best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:11] {2258} INFO - iteration 11, current learner xgboost
[flaml.automl.logger: 11-29 15:08:11] {2442} INFO -  at 0.7s,   estimator xgboost's best error=0.1080,  best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:11] {2258} INFO - iteration 12, current learner xgboost
[flaml.automl.logger: 11-29 15:08:11] {2442} INFO -  at 0.8s,   estimator xgboost's best error=0.0880,  best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:11] {2258} INFO - iteration 13, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:11] {2442} INFO -  at 1.0s,   estimator extra_tree's best error=0.0955,   best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:11] {2258} INFO - iteration 14, current learner xgboost
[flaml.automl.logger: 11-29 15:08:12] {2442} INFO -  at 1.0s,   estimator xgboost's best error=0.0880,  best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:12] {2258} INFO - iteration 15, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:12] {2442} INFO -  at 1.2s,   estimator extra_tree's best error=0.0955,   best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:12] {2258} INFO - iteration 16, current learner rf
[flaml.automl.logger: 11-29 15:08:12] {2442} INFO -  at 1.4s,   estimator rf's best error=0.0930,   best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:12] {2258} INFO - iteration 17, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:12] {2442} INFO -  at 1.5s,   estimator extra_tree's best error=0.0955,   best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:12] {2258} INFO - iteration 18, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:12] {2442} INFO -  at 1.6s,   estimator xgb_limitdepth's best error=0.0628,   best estimator xgb_limitdepth's best error=0.0628
[flaml.automl.logger: 11-29 15:08:12] {2258} INFO - iteration 19, current learner lgbm
[flaml.automl.logger: 11-29 15:08:12] {2442} INFO -  at 1.6s,   estimator lgbm's best error=0.0829, best estimator xgb_limitdepth's best error=0.0628
[flaml.automl.logger: 11-29 15:08:12] {2258} INFO - iteration 20, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:12] {2442} INFO -  at 1.7s,   estimator xgb_limitdepth's best error=0.0628,   best estimator xgb_limitdepth's best error=0.0628
[flaml.automl.logger: 11-29 15:08:12] {2258} INFO - iteration 21, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:12] {2442} INFO -  at 1.9s,   estimator extra_tree's best error=0.0955,   best estimator xgb_limitdepth's best error=0.0628
[flaml.automl.logger: 11-29 15:08:12] {2258} INFO - iteration 22, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:12] {2442} INFO -  at 2.0s,   estimator xgb_limitdepth's best error=0.0604,   best estimator xgb_limitdepth's best error=0.0604
[flaml.automl.logger: 11-29 15:08:12] {2258} INFO - iteration 23, current learner sgd
[flaml.automl.logger: 11-29 15:08:13] {2442} INFO -  at 2.1s,   estimator sgd's best error=0.0679,  best estimator xgb_limitdepth's best error=0.0604
[flaml.automl.logger: 11-29 15:08:13] {2258} INFO - iteration 24, current learner xgboost
[flaml.automl.logger: 11-29 15:08:13] {2442} INFO -  at 2.2s,   estimator xgboost's best error=0.0830,  best estimator xgb_limitdepth's best error=0.0604
[flaml.automl.logger: 11-29 15:08:13] {2258} INFO - iteration 25, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:13] {2442} INFO -  at 2.3s,   estimator extra_tree's best error=0.0955,   best estimator xgb_limitdepth's best error=0.0604
[flaml.automl.logger: 11-29 15:08:13] {2258} INFO - iteration 26, current learner sgd
[flaml.automl.logger: 11-29 15:08:13] {2442} INFO -  at 2.4s,   estimator sgd's best error=0.0679,  best estimator xgb_limitdepth's best error=0.0604
[flaml.automl.logger: 11-29 15:08:13] {2258} INFO - iteration 27, current learner sgd
[flaml.automl.logger: 11-29 15:08:13] {2442} INFO -  at 2.4s,   estimator sgd's best error=0.0554,  best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:13] {2258} INFO - iteration 28, current learner lrl1
[flaml.automl.logger: 11-29 15:08:13] {2442} INFO -  at 2.5s,   estimator lrl1's best error=0.0604, best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:13] {2258} INFO - iteration 29, current learner sgd
[flaml.automl.logger: 11-29 15:08:13] {2442} INFO -  at 2.6s,   estimator sgd's best error=0.0554,  best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:13] {2258} INFO - iteration 30, current learner lrl1
[flaml.automl.logger: 11-29 15:08:13] {2442} INFO -  at 2.7s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:13] {2258} INFO - iteration 31, current learner lrl1
[flaml.automl.logger: 11-29 15:08:13] {2442} INFO -  at 2.8s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:13] {2258} INFO - iteration 32, current learner lrl1
[flaml.automl.logger: 11-29 15:08:13] {2442} INFO -  at 2.8s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:13] {2258} INFO - iteration 33, current learner rf
[flaml.automl.logger: 11-29 15:08:13] {2442} INFO -  at 3.0s,   estimator rf's best error=0.0905,   best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:14] {2258} INFO - iteration 34, current learner lgbm
[flaml.automl.logger: 11-29 15:08:14] {2442} INFO -  at 3.0s,   estimator lgbm's best error=0.0829, best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:14] {2258} INFO - iteration 35, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:14] {2442} INFO -  at 3.2s,   estimator extra_tree's best error=0.0955,   best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:14] {2258} INFO - iteration 36, current learner lrl1
[flaml.automl.logger: 11-29 15:08:14] {2442} INFO -  at 3.3s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:14] {2258} INFO - iteration 37, current learner rf
[flaml.automl.logger: 11-29 15:08:14] {2442} INFO -  at 3.5s,   estimator rf's best error=0.0905,   best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:14] {2258} INFO - iteration 38, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:14] {2442} INFO -  at 3.5s,   estimator xgb_limitdepth's best error=0.0604,   best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:14] {2258} INFO - iteration 39, current learner lrl1
[flaml.automl.logger: 11-29 15:08:14] {2442} INFO -  at 3.6s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:14] {2258} INFO - iteration 40, current learner sgd
[flaml.automl.logger: 11-29 15:08:14] {2442} INFO -  at 3.7s,   estimator sgd's best error=0.0529,  best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:14] {2258} INFO - iteration 41, current learner sgd
[flaml.automl.logger: 11-29 15:08:14] {2442} INFO -  at 3.8s,   estimator sgd's best error=0.0529,  best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:14] {2258} INFO - iteration 42, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:14] {2442} INFO -  at 3.9s,   estimator extra_tree's best error=0.0930,   best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:14] {2258} INFO - iteration 43, current learner sgd
[flaml.automl.logger: 11-29 15:08:14] {2442} INFO -  at 4.0s,   estimator sgd's best error=0.0529,  best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:14] {2258} INFO - iteration 44, current learner sgd
[flaml.automl.logger: 11-29 15:08:14] {2442} INFO -  at 4.0s,   estimator sgd's best error=0.0529,  best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:14] {2258} INFO - iteration 45, current learner lgbm
[flaml.automl.logger: 11-29 15:08:15] {2442} INFO -  at 4.0s,   estimator lgbm's best error=0.0829, best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:15] {2258} INFO - iteration 46, current learner sgd
[flaml.automl.logger: 11-29 15:08:15] {2442} INFO -  at 4.1s,   estimator sgd's best error=0.0529,  best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:15] {2258} INFO - iteration 47, current learner lrl1
[flaml.automl.logger: 11-29 15:08:15] {2442} INFO -  at 4.1s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:15] {2258} INFO - iteration 48, current learner sgd
[flaml.automl.logger: 11-29 15:08:15] {2442} INFO -  at 4.2s,   estimator sgd's best error=0.0529,  best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:15] {2258} INFO - iteration 49, current learner xgboost
[flaml.automl.logger: 11-29 15:08:15] {2442} INFO -  at 4.3s,   estimator xgboost's best error=0.0805,  best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:15] {2258} INFO - iteration 50, current learner sgd
[flaml.automl.logger: 11-29 15:08:15] {2442} INFO -  at 4.3s,   estimator sgd's best error=0.0529,  best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:15] {2258} INFO - iteration 51, current learner lgbm
[flaml.automl.logger: 11-29 15:08:15] {2442} INFO -  at 4.3s,   estimator lgbm's best error=0.0628, best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:15] {2258} INFO - iteration 52, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:15] {2442} INFO -  at 4.4s,   estimator xgb_limitdepth's best error=0.0604,   best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:15] {2258} INFO - iteration 53, current learner lrl1
[flaml.automl.logger: 11-29 15:08:15] {2442} INFO -  at 4.5s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:15] {2258} INFO - iteration 54, current learner rf
[flaml.automl.logger: 11-29 15:08:15] {2442} INFO -  at 4.7s,   estimator rf's best error=0.0854,   best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:15] {2258} INFO - iteration 55, current learner rf
[flaml.automl.logger: 11-29 15:08:15] {2442} INFO -  at 4.9s,   estimator rf's best error=0.0804,   best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:15] {2258} INFO - iteration 56, current learner lgbm
[flaml.automl.logger: 11-29 15:08:15] {2442} INFO -  at 4.9s,   estimator lgbm's best error=0.0628, best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:15] {2258} INFO - iteration 57, current learner lgbm
[flaml.automl.logger: 11-29 15:08:15] {2442} INFO -  at 5.0s,   estimator lgbm's best error=0.0628, best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:15] {2258} INFO - iteration 58, current learner sgd
[flaml.automl.logger: 11-29 15:08:15] {2442} INFO -  at 5.0s,   estimator sgd's best error=0.0529,  best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:15] {2258} INFO - iteration 59, current learner rf
[flaml.automl.logger: 11-29 15:08:16] {2442} INFO -  at 5.2s,   estimator rf's best error=0.0804,   best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:16] {2258} INFO - iteration 60, current learner rf
[flaml.automl.logger: 11-29 15:08:16] {2442} INFO -  at 5.4s,   estimator rf's best error=0.0804,   best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:16] {2258} INFO - iteration 61, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:16] {2442} INFO -  at 5.5s,   estimator xgb_limitdepth's best error=0.0604,   best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:16] {2258} INFO - iteration 62, current learner lgbm
[flaml.automl.logger: 11-29 15:08:16] {2442} INFO -  at 5.5s,   estimator lgbm's best error=0.0628, best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:16] {2258} INFO - iteration 63, current learner sgd
[flaml.automl.logger: 11-29 15:08:16] {2442} INFO -  at 5.6s,   estimator sgd's best error=0.0529,  best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:16] {2258} INFO - iteration 64, current learner lgbm
[flaml.automl.logger: 11-29 15:08:16] {2442} INFO -  at 5.7s,   estimator lgbm's best error=0.0603, best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:16] {2258} INFO - iteration 65, current learner sgd
[flaml.automl.logger: 11-29 15:08:16] {2442} INFO -  at 5.8s,   estimator sgd's best error=0.0529,  best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:16] {2258} INFO - iteration 66, current learner sgd
[flaml.automl.logger: 11-29 15:08:16] {2442} INFO -  at 5.8s,   estimator sgd's best error=0.0479,  best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:16] {2258} INFO - iteration 67, current learner lgbm
[flaml.automl.logger: 11-29 15:08:16] {2442} INFO -  at 5.8s,   estimator lgbm's best error=0.0603, best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:16] {2258} INFO - iteration 68, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:16] {2442} INFO -  at 5.9s,   estimator xgb_limitdepth's best error=0.0604,   best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:16] {2258} INFO - iteration 69, current learner sgd
[flaml.automl.logger: 11-29 15:08:16] {2442} INFO -  at 6.0s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:16] {2258} INFO - iteration 70, current learner sgd
[flaml.automl.logger: 11-29 15:08:16] {2442} INFO -  at 6.0s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:16] {2258} INFO - iteration 71, current learner xgboost
[flaml.automl.logger: 11-29 15:08:17] {2442} INFO -  at 6.1s,   estimator xgboost's best error=0.0805,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:17] {2258} INFO - iteration 72, current learner sgd
[flaml.automl.logger: 11-29 15:08:17] {2442} INFO -  at 6.1s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:17] {2258} INFO - iteration 73, current learner sgd
[flaml.automl.logger: 11-29 15:08:17] {2442} INFO -  at 6.1s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:17] {2258} INFO - iteration 74, current learner sgd
[flaml.automl.logger: 11-29 15:08:17] {2442} INFO -  at 6.2s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:17] {2258} INFO - iteration 75, current learner sgd
[flaml.automl.logger: 11-29 15:08:17] {2442} INFO -  at 6.2s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:17] {2258} INFO - iteration 76, current learner sgd
[flaml.automl.logger: 11-29 15:08:17] {2442} INFO -  at 6.3s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:17] {2258} INFO - iteration 77, current learner sgd
[flaml.automl.logger: 11-29 15:08:17] {2442} INFO -  at 6.3s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:17] {2258} INFO - iteration 78, current learner rf
[flaml.automl.logger: 11-29 15:08:17] {2442} INFO -  at 6.5s,   estimator rf's best error=0.0804,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:17] {2258} INFO - iteration 79, current learner rf
[flaml.automl.logger: 11-29 15:08:17] {2442} INFO -  at 6.7s,   estimator rf's best error=0.0804,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:17] {2258} INFO - iteration 80, current learner sgd
[flaml.automl.logger: 11-29 15:08:17] {2442} INFO -  at 6.7s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:17] {2258} INFO - iteration 81, current learner sgd
[flaml.automl.logger: 11-29 15:08:17] {2442} INFO -  at 6.8s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:17] {2258} INFO - iteration 82, current learner xgboost
[flaml.automl.logger: 11-29 15:08:17] {2442} INFO -  at 6.9s,   estimator xgboost's best error=0.0805,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:17] {2258} INFO - iteration 83, current learner lrl1
[flaml.automl.logger: 11-29 15:08:17] {2442} INFO -  at 6.9s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:17] {2258} INFO - iteration 84, current learner sgd
[flaml.automl.logger: 11-29 15:08:17] {2442} INFO -  at 7.0s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:17] {2258} INFO - iteration 85, current learner sgd
[flaml.automl.logger: 11-29 15:08:18] {2442} INFO -  at 7.1s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:18] {2258} INFO - iteration 86, current learner sgd
[flaml.automl.logger: 11-29 15:08:18] {2442} INFO -  at 7.1s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:18] {2258} INFO - iteration 87, current learner sgd
[flaml.automl.logger: 11-29 15:08:18] {2442} INFO -  at 7.2s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:18] {2258} INFO - iteration 88, current learner sgd
[flaml.automl.logger: 11-29 15:08:18] {2442} INFO -  at 7.2s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:18] {2258} INFO - iteration 89, current learner sgd
[flaml.automl.logger: 11-29 15:08:18] {2442} INFO -  at 7.2s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:18] {2258} INFO - iteration 90, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:18] {2442} INFO -  at 7.3s,   estimator xgb_limitdepth's best error=0.0604,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:18] {2258} INFO - iteration 91, current learner xgboost
[flaml.automl.logger: 11-29 15:08:18] {2442} INFO -  at 7.4s,   estimator xgboost's best error=0.0754,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:18] {2258} INFO - iteration 92, current learner sgd
[flaml.automl.logger: 11-29 15:08:18] {2442} INFO -  at 7.5s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:18] {2258} INFO - iteration 93, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:18] {2442} INFO -  at 7.5s,   estimator xgb_limitdepth's best error=0.0604,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:18] {2258} INFO - iteration 94, current learner lrl1
[flaml.automl.logger: 11-29 15:08:18] {2442} INFO -  at 7.6s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:18] {2258} INFO - iteration 95, current learner sgd
[flaml.automl.logger: 11-29 15:08:18] {2442} INFO -  at 7.6s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:18] {2258} INFO - iteration 96, current learner sgd
[flaml.automl.logger: 11-29 15:08:18] {2442} INFO -  at 7.7s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:18] {2258} INFO - iteration 97, current learner lgbm
[flaml.automl.logger: 11-29 15:08:18] {2442} INFO -  at 7.7s,   estimator lgbm's best error=0.0603, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:18] {2258} INFO - iteration 98, current learner lrl1
[flaml.automl.logger: 11-29 15:08:18] {2442} INFO -  at 7.8s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:18] {2258} INFO - iteration 99, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:18] {2442} INFO -  at 7.9s,   estimator xgb_limitdepth's best error=0.0604,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:18] {2258} INFO - iteration 100, current learner sgd
[flaml.automl.logger: 11-29 15:08:18] {2442} INFO -  at 7.9s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:18] {2258} INFO - iteration 101, current learner xgboost
[flaml.automl.logger: 11-29 15:08:18] {2442} INFO -  at 8.0s,   estimator xgboost's best error=0.0754,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:18] {2258} INFO - iteration 102, current learner xgboost
[flaml.automl.logger: 11-29 15:08:19] {2442} INFO -  at 8.1s,   estimator xgboost's best error=0.0754,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:19] {2258} INFO - iteration 103, current learner sgd
[flaml.automl.logger: 11-29 15:08:19] {2442} INFO -  at 8.1s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:19] {2258} INFO - iteration 104, current learner sgd
[flaml.automl.logger: 11-29 15:08:19] {2442} INFO -  at 8.2s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:19] {2258} INFO - iteration 105, current learner lgbm
[flaml.automl.logger: 11-29 15:08:19] {2442} INFO -  at 8.2s,   estimator lgbm's best error=0.0603, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:19] {2258} INFO - iteration 106, current learner sgd
[flaml.automl.logger: 11-29 15:08:19] {2442} INFO -  at 8.3s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:19] {2258} INFO - iteration 107, current learner xgboost
[flaml.automl.logger: 11-29 15:08:19] {2442} INFO -  at 8.3s,   estimator xgboost's best error=0.0754,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:19] {2258} INFO - iteration 108, current learner sgd
[flaml.automl.logger: 11-29 15:08:19] {2442} INFO -  at 8.4s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:19] {2258} INFO - iteration 109, current learner sgd
[flaml.automl.logger: 11-29 15:08:19] {2442} INFO -  at 8.4s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:19] {2258} INFO - iteration 110, current learner xgboost
[flaml.automl.logger: 11-29 15:08:19] {2442} INFO -  at 8.5s,   estimator xgboost's best error=0.0754,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:19] {2258} INFO - iteration 111, current learner lrl1
[flaml.automl.logger: 11-29 15:08:19] {2442} INFO -  at 8.6s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:19] {2258} INFO - iteration 112, current learner sgd
[flaml.automl.logger: 11-29 15:08:19] {2442} INFO -  at 8.6s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:19] {2258} INFO - iteration 113, current learner lgbm
[flaml.automl.logger: 11-29 15:08:19] {2442} INFO -  at 8.7s,   estimator lgbm's best error=0.0603, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:19] {2258} INFO - iteration 114, current learner lrl1
[flaml.automl.logger: 11-29 15:08:19] {2442} INFO -  at 8.7s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:19] {2258} INFO - iteration 115, current learner sgd
[flaml.automl.logger: 11-29 15:08:19] {2442} INFO -  at 8.8s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:19] {2258} INFO - iteration 116, current learner lrl1
[flaml.automl.logger: 11-29 15:08:19] {2442} INFO -  at 8.9s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:19] {2258} INFO - iteration 117, current learner rf
[flaml.automl.logger: 11-29 15:08:20] {2442} INFO -  at 9.1s,   estimator rf's best error=0.0804,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:20] {2258} INFO - iteration 118, current learner rf
[flaml.automl.logger: 11-29 15:08:20] {2442} INFO -  at 9.2s,   estimator rf's best error=0.0804,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:20] {2258} INFO - iteration 119, current learner lrl1
[flaml.automl.logger: 11-29 15:08:20] {2442} INFO -  at 9.3s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:20] {2258} INFO - iteration 120, current learner sgd
[flaml.automl.logger: 11-29 15:08:20] {2442} INFO -  at 9.4s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:20] {2258} INFO - iteration 121, current learner lgbm
[flaml.automl.logger: 11-29 15:08:20] {2442} INFO -  at 9.4s,   estimator lgbm's best error=0.0603, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:20] {2258} INFO - iteration 122, current learner sgd
[flaml.automl.logger: 11-29 15:08:20] {2442} INFO -  at 9.4s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:20] {2258} INFO - iteration 123, current learner sgd
[flaml.automl.logger: 11-29 15:08:20] {2442} INFO -  at 9.5s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:20] {2258} INFO - iteration 124, current learner lrl1
[flaml.automl.logger: 11-29 15:08:20] {2442} INFO -  at 9.6s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:20] {2258} INFO - iteration 125, current learner sgd
[flaml.automl.logger: 11-29 15:08:20] {2442} INFO -  at 9.7s,   estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:20] {2258} INFO - iteration 126, current learner rf
[flaml.automl.logger: 11-29 15:08:20] {2442} INFO -  at 9.8s,   estimator rf's best error=0.0804,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:20] {2258} INFO - iteration 127, current learner lgbm
[flaml.automl.logger: 11-29 15:08:20] {2442} INFO -  at 9.9s,   estimator lgbm's best error=0.0603, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:20] {2258} INFO - iteration 128, current learner lgbm
[flaml.automl.logger: 11-29 15:08:20] {2442} INFO -  at 9.9s,   estimator lgbm's best error=0.0603, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:20] {2258} INFO - iteration 129, current learner lgbm
[flaml.automl.logger: 11-29 15:08:20] {2442} INFO -  at 9.9s,   estimator lgbm's best error=0.0603, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:20] {2258} INFO - iteration 130, current learner xgboost
[flaml.automl.logger: 11-29 15:08:21] {2442} INFO -  at 10.0s,  estimator xgboost's best error=0.0728,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:21] {2258} INFO - iteration 131, current learner sgd
[flaml.automl.logger: 11-29 15:08:21] {2442} INFO -  at 10.0s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:21] {2258} INFO - iteration 132, current learner sgd
[flaml.automl.logger: 11-29 15:08:21] {2442} INFO -  at 10.1s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:21] {2258} INFO - iteration 133, current learner sgd
[flaml.automl.logger: 11-29 15:08:21] {2442} INFO -  at 10.1s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:21] {2258} INFO - iteration 134, current learner sgd
[flaml.automl.logger: 11-29 15:08:21] {2442} INFO -  at 10.2s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:21] {2258} INFO - iteration 135, current learner rf
[flaml.automl.logger: 11-29 15:08:21] {2442} INFO -  at 10.3s,  estimator rf's best error=0.0804,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:21] {2258} INFO - iteration 136, current learner xgboost
[flaml.automl.logger: 11-29 15:08:21] {2442} INFO -  at 10.4s,  estimator xgboost's best error=0.0653,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:21] {2258} INFO - iteration 137, current learner xgboost
[flaml.automl.logger: 11-29 15:08:21] {2442} INFO -  at 10.5s,  estimator xgboost's best error=0.0653,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:21] {2258} INFO - iteration 138, current learner lrl1
[flaml.automl.logger: 11-29 15:08:21] {2442} INFO -  at 10.6s,  estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:21] {2258} INFO - iteration 139, current learner xgboost
[flaml.automl.logger: 11-29 15:08:21] {2442} INFO -  at 10.7s,  estimator xgboost's best error=0.0653,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:21] {2258} INFO - iteration 140, current learner lgbm
[flaml.automl.logger: 11-29 15:08:21] {2442} INFO -  at 10.7s,  estimator lgbm's best error=0.0603, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:21] {2258} INFO - iteration 141, current learner sgd
[flaml.automl.logger: 11-29 15:08:21] {2442} INFO -  at 10.8s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:21] {2258} INFO - iteration 142, current learner xgboost
[flaml.automl.logger: 11-29 15:08:21] {2442} INFO -  at 10.9s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:21] {2258} INFO - iteration 143, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:22] {2442} INFO -  at 11.0s,  estimator extra_tree's best error=0.0930,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:22] {2258} INFO - iteration 144, current learner xgboost
[flaml.automl.logger: 11-29 15:08:22] {2442} INFO -  at 11.1s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:22] {2258} INFO - iteration 145, current learner sgd
[flaml.automl.logger: 11-29 15:08:22] {2442} INFO -  at 11.1s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:22] {2258} INFO - iteration 146, current learner xgboost
[flaml.automl.logger: 11-29 15:08:22] {2442} INFO -  at 11.3s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:22] {2258} INFO - iteration 147, current learner xgboost
[flaml.automl.logger: 11-29 15:08:22] {2442} INFO -  at 11.4s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:22] {2258} INFO - iteration 148, current learner xgboost
[flaml.automl.logger: 11-29 15:08:22] {2442} INFO -  at 11.4s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:22] {2258} INFO - iteration 149, current learner rf
[flaml.automl.logger: 11-29 15:08:22] {2442} INFO -  at 11.6s,  estimator rf's best error=0.0804,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:22] {2258} INFO - iteration 150, current learner xgboost
[flaml.automl.logger: 11-29 15:08:22] {2442} INFO -  at 11.8s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:22] {2258} INFO - iteration 151, current learner lgbm
[flaml.automl.logger: 11-29 15:08:22] {2442} INFO -  at 11.8s,  estimator lgbm's best error=0.0603, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:22] {2258} INFO - iteration 152, current learner rf
[flaml.automl.logger: 11-29 15:08:22] {2442} INFO -  at 12.0s,  estimator rf's best error=0.0804,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:22] {2258} INFO - iteration 153, current learner xgboost
[flaml.automl.logger: 11-29 15:08:23] {2442} INFO -  at 12.1s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:23] {2258} INFO - iteration 154, current learner sgd
[flaml.automl.logger: 11-29 15:08:23] {2442} INFO -  at 12.1s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:23] {2258} INFO - iteration 155, current learner xgboost
[flaml.automl.logger: 11-29 15:08:23] {2442} INFO -  at 12.2s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:23] {2258} INFO - iteration 156, current learner lgbm
[flaml.automl.logger: 11-29 15:08:23] {2442} INFO -  at 12.3s,  estimator lgbm's best error=0.0603, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:23] {2258} INFO - iteration 157, current learner rf
[flaml.automl.logger: 11-29 15:08:23] {2442} INFO -  at 12.5s,  estimator rf's best error=0.0804,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:23] {2258} INFO - iteration 158, current learner lrl1
[flaml.automl.logger: 11-29 15:08:23] {2442} INFO -  at 12.5s,  estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:23] {2258} INFO - iteration 159, current learner xgboost
[flaml.automl.logger: 11-29 15:08:23] {2442} INFO -  at 12.6s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:23] {2258} INFO - iteration 160, current learner xgboost
[flaml.automl.logger: 11-29 15:08:23] {2442} INFO -  at 12.8s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:23] {2258} INFO - iteration 161, current learner xgboost
[flaml.automl.logger: 11-29 15:08:23] {2442} INFO -  at 12.9s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:23] {2258} INFO - iteration 162, current learner sgd
[flaml.automl.logger: 11-29 15:08:23] {2442} INFO -  at 12.9s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:23] {2258} INFO - iteration 163, current learner xgboost
[flaml.automl.logger: 11-29 15:08:24] {2442} INFO -  at 13.0s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:24] {2258} INFO - iteration 164, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:24] {2442} INFO -  at 13.1s,  estimator xgb_limitdepth's best error=0.0604,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:24] {2258} INFO - iteration 165, current learner lrl1
[flaml.automl.logger: 11-29 15:08:24] {2442} INFO -  at 13.2s,  estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:24] {2258} INFO - iteration 166, current learner sgd
[flaml.automl.logger: 11-29 15:08:24] {2442} INFO -  at 13.2s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:24] {2258} INFO - iteration 167, current learner xgboost
[flaml.automl.logger: 11-29 15:08:24] {2442} INFO -  at 13.4s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:24] {2258} INFO - iteration 168, current learner xgboost
[flaml.automl.logger: 11-29 15:08:24] {2442} INFO -  at 13.5s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:24] {2258} INFO - iteration 169, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:24] {2442} INFO -  at 13.5s,  estimator xgb_limitdepth's best error=0.0604,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:24] {2258} INFO - iteration 170, current learner sgd
[flaml.automl.logger: 11-29 15:08:24] {2442} INFO -  at 13.7s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:24] {2258} INFO - iteration 171, current learner xgboost
[flaml.automl.logger: 11-29 15:08:24] {2442} INFO -  at 13.8s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:24] {2258} INFO - iteration 172, current learner lgbm
[flaml.automl.logger: 11-29 15:08:24] {2442} INFO -  at 13.8s,  estimator lgbm's best error=0.0603, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:24] {2258} INFO - iteration 173, current learner rf
[flaml.automl.logger: 11-29 15:08:24] {2442} INFO -  at 14.0s,  estimator rf's best error=0.0804,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:24] {2258} INFO - iteration 174, current learner xgboost
[flaml.automl.logger: 11-29 15:08:25] {2442} INFO -  at 14.1s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:25] {2258} INFO - iteration 175, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:25] {2442} INFO -  at 14.2s,  estimator xgb_limitdepth's best error=0.0579,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:25] {2258} INFO - iteration 176, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:25] {2442} INFO -  at 14.3s,  estimator xgb_limitdepth's best error=0.0579,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:25] {2258} INFO - iteration 177, current learner xgboost
[flaml.automl.logger: 11-29 15:08:25] {2442} INFO -  at 14.4s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:25] {2258} INFO - iteration 178, current learner lrl1
[flaml.automl.logger: 11-29 15:08:25] {2442} INFO -  at 14.5s,  estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:25] {2258} INFO - iteration 179, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:25] {2442} INFO -  at 14.6s,  estimator xgb_limitdepth's best error=0.0579,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:25] {2258} INFO - iteration 180, current learner xgboost
[flaml.automl.logger: 11-29 15:08:25] {2442} INFO -  at 14.7s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:25] {2258} INFO - iteration 181, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:25] {2442} INFO -  at 14.8s,  estimator xgb_limitdepth's best error=0.0579,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:25] {2258} INFO - iteration 182, current learner sgd
[flaml.automl.logger: 11-29 15:08:25] {2442} INFO -  at 14.8s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:25] {2258} INFO - iteration 183, current learner sgd
[flaml.automl.logger: 11-29 15:08:25] {2442} INFO -  at 14.8s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:25] {2258} INFO - iteration 184, current learner xgboost
[flaml.automl.logger: 11-29 15:08:25] {2442} INFO -  at 15.0s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:25] {2258} INFO - iteration 185, current learner lgbm
[flaml.automl.logger: 11-29 15:08:25] {2442} INFO -  at 15.0s,  estimator lgbm's best error=0.0578, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:25] {2258} INFO - iteration 186, current learner xgboost
[flaml.automl.logger: 11-29 15:08:26] {2442} INFO -  at 15.1s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:26] {2258} INFO - iteration 187, current learner sgd
[flaml.automl.logger: 11-29 15:08:26] {2442} INFO -  at 15.2s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:26] {2258} INFO - iteration 188, current learner xgboost
[flaml.automl.logger: 11-29 15:08:26] {2442} INFO -  at 15.4s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:26] {2258} INFO - iteration 189, current learner sgd
[flaml.automl.logger: 11-29 15:08:26] {2442} INFO -  at 15.4s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:26] {2258} INFO - iteration 190, current learner lgbm
[flaml.automl.logger: 11-29 15:08:26] {2442} INFO -  at 15.5s,  estimator lgbm's best error=0.0578, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:26] {2258} INFO - iteration 191, current learner xgboost
[flaml.automl.logger: 11-29 15:08:26] {2442} INFO -  at 15.6s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:26] {2258} INFO - iteration 192, current learner sgd
[flaml.automl.logger: 11-29 15:08:26] {2442} INFO -  at 15.6s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:26] {2258} INFO - iteration 193, current learner xgboost
[flaml.automl.logger: 11-29 15:08:26] {2442} INFO -  at 15.7s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:26] {2258} INFO - iteration 194, current learner sgd
[flaml.automl.logger: 11-29 15:08:26] {2442} INFO -  at 15.8s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:26] {2258} INFO - iteration 195, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:26] {2442} INFO -  at 15.9s,  estimator xgb_limitdepth's best error=0.0579,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:26] {2258} INFO - iteration 196, current learner lrl1
[flaml.automl.logger: 11-29 15:08:26] {2442} INFO -  at 15.9s,  estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:26] {2258} INFO - iteration 197, current learner xgboost
[flaml.automl.logger: 11-29 15:08:27] {2442} INFO -  at 16.0s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:27] {2258} INFO - iteration 198, current learner rf
[flaml.automl.logger: 11-29 15:08:27] {2442} INFO -  at 16.2s,  estimator rf's best error=0.0804,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:27] {2258} INFO - iteration 199, current learner sgd
[flaml.automl.logger: 11-29 15:08:27] {2442} INFO -  at 16.2s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:27] {2258} INFO - iteration 200, current learner sgd
[flaml.automl.logger: 11-29 15:08:27] {2442} INFO -  at 16.3s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:27] {2258} INFO - iteration 201, current learner sgd
[flaml.automl.logger: 11-29 15:08:27] {2442} INFO -  at 16.3s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:27] {2258} INFO - iteration 202, current learner lrl1
[flaml.automl.logger: 11-29 15:08:27] {2442} INFO -  at 16.4s,  estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:27] {2258} INFO - iteration 203, current learner lgbm
[flaml.automl.logger: 11-29 15:08:27] {2442} INFO -  at 16.5s,  estimator lgbm's best error=0.0578, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:27] {2258} INFO - iteration 204, current learner xgboost
[flaml.automl.logger: 11-29 15:08:27] {2442} INFO -  at 16.6s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:27] {2258} INFO - iteration 205, current learner sgd
[flaml.automl.logger: 11-29 15:08:27] {2442} INFO -  at 16.6s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:27] {2258} INFO - iteration 206, current learner lrl1
[flaml.automl.logger: 11-29 15:08:27] {2442} INFO -  at 16.7s,  estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:27] {2258} INFO - iteration 207, current learner lrl1
[flaml.automl.logger: 11-29 15:08:27] {2442} INFO -  at 16.8s,  estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:27] {2258} INFO - iteration 208, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:27] {2442} INFO -  at 16.9s,  estimator xgb_limitdepth's best error=0.0578,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:27] {2258} INFO - iteration 209, current learner sgd
[flaml.automl.logger: 11-29 15:08:27] {2442} INFO -  at 17.0s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:27] {2258} INFO - iteration 210, current learner sgd
[flaml.automl.logger: 11-29 15:08:27] {2442} INFO -  at 17.0s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:27] {2258} INFO - iteration 211, current learner xgboost
[flaml.automl.logger: 11-29 15:08:28] {2442} INFO -  at 17.1s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:28] {2258} INFO - iteration 212, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:28] {2442} INFO -  at 17.3s,  estimator extra_tree's best error=0.0930,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:28] {2258} INFO - iteration 213, current learner sgd
[flaml.automl.logger: 11-29 15:08:28] {2442} INFO -  at 17.3s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:28] {2258} INFO - iteration 214, current learner sgd
[flaml.automl.logger: 11-29 15:08:28] {2442} INFO -  at 17.3s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:28] {2258} INFO - iteration 215, current learner lrl1
[flaml.automl.logger: 11-29 15:08:28] {2442} INFO -  at 17.4s,  estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:28] {2258} INFO - iteration 216, current learner lrl1
[flaml.automl.logger: 11-29 15:08:28] {2442} INFO -  at 17.5s,  estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:28] {2258} INFO - iteration 217, current learner xgboost
[flaml.automl.logger: 11-29 15:08:28] {2442} INFO -  at 17.6s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:28] {2258} INFO - iteration 218, current learner lrl1
[flaml.automl.logger: 11-29 15:08:28] {2442} INFO -  at 17.6s,  estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:28] {2258} INFO - iteration 219, current learner xgboost
[flaml.automl.logger: 11-29 15:08:28] {2442} INFO -  at 17.8s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:28] {2258} INFO - iteration 220, current learner xgboost
[flaml.automl.logger: 11-29 15:08:28] {2442} INFO -  at 17.9s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:28] {2258} INFO - iteration 221, current learner xgboost
[flaml.automl.logger: 11-29 15:08:28] {2442} INFO -  at 18.0s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:28] {2258} INFO - iteration 222, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:29] {2442} INFO -  at 18.1s,  estimator extra_tree's best error=0.0930,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:29] {2258} INFO - iteration 223, current learner rf
[flaml.automl.logger: 11-29 15:08:29] {2442} INFO -  at 18.4s,  estimator rf's best error=0.0804,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:29] {2258} INFO - iteration 224, current learner lrl1
[flaml.automl.logger: 11-29 15:08:29] {2442} INFO -  at 18.4s,  estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:29] {2258} INFO - iteration 225, current learner sgd
[flaml.automl.logger: 11-29 15:08:29] {2442} INFO -  at 18.5s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:29] {2258} INFO - iteration 226, current learner rf
[flaml.automl.logger: 11-29 15:08:29] {2442} INFO -  at 18.7s,  estimator rf's best error=0.0804,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:29] {2258} INFO - iteration 227, current learner xgboost
[flaml.automl.logger: 11-29 15:08:29] {2442} INFO -  at 18.8s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:29] {2258} INFO - iteration 228, current learner xgboost
[flaml.automl.logger: 11-29 15:08:29] {2442} INFO -  at 18.9s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:29] {2258} INFO - iteration 229, current learner xgboost
[flaml.automl.logger: 11-29 15:08:29] {2442} INFO -  at 19.0s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:29] {2258} INFO - iteration 230, current learner sgd
[flaml.automl.logger: 11-29 15:08:30] {2442} INFO -  at 19.1s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:30] {2258} INFO - iteration 231, current learner xgboost
[flaml.automl.logger: 11-29 15:08:30] {2442} INFO -  at 19.2s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:30] {2258} INFO - iteration 232, current learner lrl1
[flaml.automl.logger: 11-29 15:08:30] {2442} INFO -  at 19.3s,  estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:30] {2258} INFO - iteration 233, current learner sgd
[flaml.automl.logger: 11-29 15:08:30] {2442} INFO -  at 19.3s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:30] {2258} INFO - iteration 234, current learner sgd
[flaml.automl.logger: 11-29 15:08:30] {2442} INFO -  at 19.4s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:30] {2258} INFO - iteration 235, current learner sgd
[flaml.automl.logger: 11-29 15:08:30] {2442} INFO -  at 19.4s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:30] {2258} INFO - iteration 236, current learner sgd
[flaml.automl.logger: 11-29 15:08:30] {2442} INFO -  at 19.4s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:30] {2258} INFO - iteration 237, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:30] {2442} INFO -  at 19.6s,  estimator extra_tree's best error=0.0930,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:30] {2258} INFO - iteration 238, current learner sgd
[flaml.automl.logger: 11-29 15:08:30] {2442} INFO -  at 19.7s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:30] {2258} INFO - iteration 239, current learner sgd
[flaml.automl.logger: 11-29 15:08:30] {2442} INFO -  at 19.7s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:30] {2258} INFO - iteration 240, current learner xgboost
[flaml.automl.logger: 11-29 15:08:30] {2442} INFO -  at 19.9s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:30] {2258} INFO - iteration 241, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:31] {2442} INFO -  at 20.0s,  estimator extra_tree's best error=0.0804,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:31] {2258} INFO - iteration 242, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:31] {2442} INFO -  at 20.2s,  estimator extra_tree's best error=0.0804,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:31] {2258} INFO - iteration 243, current learner rf
[flaml.automl.logger: 11-29 15:08:31] {2442} INFO -  at 20.4s,  estimator rf's best error=0.0804,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:31] {2258} INFO - iteration 244, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:31] {2442} INFO -  at 20.5s,  estimator extra_tree's best error=0.0755,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:31] {2258} INFO - iteration 245, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:31] {2442} INFO -  at 20.7s,  estimator extra_tree's best error=0.0755,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:31] {2258} INFO - iteration 246, current learner sgd
[flaml.automl.logger: 11-29 15:08:31] {2442} INFO -  at 20.7s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:31] {2258} INFO - iteration 247, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:31] {2442} INFO -  at 20.9s,  estimator extra_tree's best error=0.0755,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:31] {2258} INFO - iteration 248, current learner sgd
[flaml.automl.logger: 11-29 15:08:31] {2442} INFO -  at 20.9s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:31] {2258} INFO - iteration 249, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:32] {2442} INFO -  at 21.1s,  estimator extra_tree's best error=0.0755,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:32] {2258} INFO - iteration 250, current learner xgboost
[flaml.automl.logger: 11-29 15:08:32] {2442} INFO -  at 21.2s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:32] {2258} INFO - iteration 251, current learner sgd
[flaml.automl.logger: 11-29 15:08:32] {2442} INFO -  at 21.3s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:32] {2258} INFO - iteration 252, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:32] {2442} INFO -  at 21.5s,  estimator extra_tree's best error=0.0755,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:32] {2258} INFO - iteration 253, current learner rf
[flaml.automl.logger: 11-29 15:08:32] {2442} INFO -  at 21.6s,  estimator rf's best error=0.0804,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:32] {2258} INFO - iteration 254, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:32] {2442} INFO -  at 21.8s,  estimator extra_tree's best error=0.0755,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:32] {2258} INFO - iteration 255, current learner sgd
[flaml.automl.logger: 11-29 15:08:32] {2442} INFO -  at 21.8s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:32] {2258} INFO - iteration 256, current learner sgd
[flaml.automl.logger: 11-29 15:08:32] {2442} INFO -  at 21.9s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:32] {2258} INFO - iteration 257, current learner lgbm
[flaml.automl.logger: 11-29 15:08:32] {2442} INFO -  at 21.9s,  estimator lgbm's best error=0.0553, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:32] {2258} INFO - iteration 258, current learner lrl1
[flaml.automl.logger: 11-29 15:08:32] {2442} INFO -  at 22.0s,  estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:32] {2258} INFO - iteration 259, current learner lgbm
[flaml.automl.logger: 11-29 15:08:33] {2442} INFO -  at 22.1s,  estimator lgbm's best error=0.0553, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:33] {2258} INFO - iteration 260, current learner lrl1
[flaml.automl.logger: 11-29 15:08:33] {2442} INFO -  at 22.1s,  estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:33] {2258} INFO - iteration 261, current learner xgboost
[flaml.automl.logger: 11-29 15:08:33] {2442} INFO -  at 22.2s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:33] {2258} INFO - iteration 262, current learner sgd
[flaml.automl.logger: 11-29 15:08:33] {2442} INFO -  at 22.3s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:33] {2258} INFO - iteration 263, current learner xgboost
[flaml.automl.logger: 11-29 15:08:33] {2442} INFO -  at 22.4s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:33] {2258} INFO - iteration 264, current learner xgboost
[flaml.automl.logger: 11-29 15:08:33] {2442} INFO -  at 22.5s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:33] {2258} INFO - iteration 265, current learner lgbm
[flaml.automl.logger: 11-29 15:08:33] {2442} INFO -  at 22.5s,  estimator lgbm's best error=0.0553, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:33] {2258} INFO - iteration 266, current learner xgboost
[flaml.automl.logger: 11-29 15:08:33] {2442} INFO -  at 22.7s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:33] {2258} INFO - iteration 267, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:33] {2442} INFO -  at 22.8s,  estimator extra_tree's best error=0.0755,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:33] {2258} INFO - iteration 268, current learner sgd
[flaml.automl.logger: 11-29 15:08:33] {2442} INFO -  at 22.9s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:33] {2258} INFO - iteration 269, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:34] {2442} INFO -  at 23.0s,  estimator extra_tree's best error=0.0755,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:34] {2258} INFO - iteration 270, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:34] {2442} INFO -  at 23.2s,  estimator extra_tree's best error=0.0755,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:34] {2258} INFO - iteration 271, current learner sgd
[flaml.automl.logger: 11-29 15:08:34] {2442} INFO -  at 23.3s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:34] {2258} INFO - iteration 272, current learner lgbm
[flaml.automl.logger: 11-29 15:08:34] {2442} INFO -  at 23.3s,  estimator lgbm's best error=0.0553, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:34] {2258} INFO - iteration 273, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:34] {2442} INFO -  at 23.5s,  estimator extra_tree's best error=0.0755,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:34] {2258} INFO - iteration 274, current learner xgboost
[flaml.automl.logger: 11-29 15:08:34] {2442} INFO -  at 23.6s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:34] {2258} INFO - iteration 275, current learner rf
[flaml.automl.logger: 11-29 15:08:34] {2442} INFO -  at 23.8s,  estimator rf's best error=0.0804,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:34] {2258} INFO - iteration 276, current learner rf
[flaml.automl.logger: 11-29 15:08:34] {2442} INFO -  at 24.0s,  estimator rf's best error=0.0804,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:34] {2258} INFO - iteration 277, current learner rf
[flaml.automl.logger: 11-29 15:08:35] {2442} INFO -  at 24.1s,  estimator rf's best error=0.0804,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:35] {2258} INFO - iteration 278, current learner lgbm
[flaml.automl.logger: 11-29 15:08:35] {2442} INFO -  at 24.2s,  estimator lgbm's best error=0.0553, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:35] {2258} INFO - iteration 279, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:35] {2442} INFO -  at 24.3s,  estimator extra_tree's best error=0.0755,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:35] {2258} INFO - iteration 280, current learner xgboost
[flaml.automl.logger: 11-29 15:08:35] {2442} INFO -  at 24.4s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:35] {2258} INFO - iteration 281, current learner lrl1
[flaml.automl.logger: 11-29 15:08:35] {2442} INFO -  at 24.5s,  estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:35] {2258} INFO - iteration 282, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:35] {2442} INFO -  at 24.7s,  estimator extra_tree's best error=0.0679,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:35] {2258} INFO - iteration 283, current learner lgbm
[flaml.automl.logger: 11-29 15:08:35] {2442} INFO -  at 24.7s,  estimator lgbm's best error=0.0528, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:35] {2258} INFO - iteration 284, current learner rf
[flaml.automl.logger: 11-29 15:08:35] {2442} INFO -  at 24.9s,  estimator rf's best error=0.0804,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:35] {2258} INFO - iteration 285, current learner lgbm
[flaml.automl.logger: 11-29 15:08:35] {2442} INFO -  at 24.9s,  estimator lgbm's best error=0.0528, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:35] {2258} INFO - iteration 286, current learner sgd
[flaml.automl.logger: 11-29 15:08:35] {2442} INFO -  at 25.0s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:35] {2258} INFO - iteration 287, current learner sgd
[flaml.automl.logger: 11-29 15:08:36] {2442} INFO -  at 25.0s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:36] {2258} INFO - iteration 288, current learner sgd
[flaml.automl.logger: 11-29 15:08:36] {2442} INFO -  at 25.1s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:36] {2258} INFO - iteration 289, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:36] {2442} INFO -  at 25.2s,  estimator extra_tree's best error=0.0679,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:36] {2258} INFO - iteration 290, current learner lgbm
[flaml.automl.logger: 11-29 15:08:36] {2442} INFO -  at 25.3s,  estimator lgbm's best error=0.0528, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:36] {2258} INFO - iteration 291, current learner lgbm
[flaml.automl.logger: 11-29 15:08:36] {2442} INFO -  at 25.3s,  estimator lgbm's best error=0.0528, best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:36] {2258} INFO - iteration 292, current learner sgd
[flaml.automl.logger: 11-29 15:08:36] {2442} INFO -  at 25.4s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:36] {2258} INFO - iteration 293, current learner xgboost
[flaml.automl.logger: 11-29 15:08:36] {2442} INFO -  at 25.5s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:36] {2258} INFO - iteration 294, current learner sgd
[flaml.automl.logger: 11-29 15:08:36] {2442} INFO -  at 25.6s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:36] {2258} INFO - iteration 295, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:36] {2442} INFO -  at 25.7s,  estimator extra_tree's best error=0.0679,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:36] {2258} INFO - iteration 296, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:36] {2442} INFO -  at 25.9s,  estimator extra_tree's best error=0.0679,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:36] {2258} INFO - iteration 297, current learner xgboost
[flaml.automl.logger: 11-29 15:08:36] {2442} INFO -  at 26.0s,  estimator xgboost's best error=0.0553,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:36] {2258} INFO - iteration 298, current learner sgd
[flaml.automl.logger: 11-29 15:08:37] {2442} INFO -  at 26.1s,  estimator sgd's best error=0.0453,  best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:37] {2258} INFO - iteration 299, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:37] {2442} INFO -  at 26.2s,  estimator extra_tree's best error=0.0679,   best estimator sgd's best error=0.0453
[flaml.automl.logger: 11-29 15:08:37] {2685} INFO - retrain sgd for 0.0s
[flaml.automl.logger: 11-29 15:08:37] {2688} INFO - retrained model: SGDClassifier(alpha=np.float64(7.734282955563902e-05),
              epsilon=np.float64(0.004338715346995631),
              eta0=np.float64(0.006251777605333116),
              l1_ratio=np.float64(0.0029250495014144875),
              learning_rate='invscaling', loss=np.str_('modified_huber'),
              n_jobs=-1, penalty=np.str_('elasticnet'),
              power_t=np.float64(0.08067506383144306), tol=0.0001)
[flaml.automl.logger: 11-29 15:08:37] {1985} INFO - fit succeeded
[flaml.automl.logger: 11-29 15:08:37] {1986} INFO - Time taken to find the best model: 5.9653191566467285</code></pre>
</div>
</div>
</section>

<section id="section-3" class="title-slide slide level1 center">
<h1></h1>
<div id="cell-72" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:37.244553Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:37.244219Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:37.249695Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:37.249105Z&quot;}" data-execution_count="39">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb51-1"><a href=""></a>automl.model.estimator</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="39">
<style>#sk-container-id-5 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-5 {
  color: var(--sklearn-color-text);
}

#sk-container-id-5 pre {
  padding: 0;
}

#sk-container-id-5 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-5 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-5 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-5 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-5 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-5 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-5 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-5 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-5 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-5 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-5 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-5 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-5 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-5 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-5 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-5 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-5 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-5 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-5 div.sk-label label.sk-toggleable__label,
#sk-container-id-5 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-5 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-5 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-5 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-5 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-5 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-5 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-5 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-5 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-5 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-5 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-5" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>SGDClassifier(alpha=np.float64(7.734282955563902e-05),
              epsilon=np.float64(0.004338715346995631),
              eta0=np.float64(0.006251777605333116),
              l1_ratio=np.float64(0.0029250495014144875),
              learning_rate='invscaling', loss=np.str_('modified_huber'),
              n_jobs=-1, penalty=np.str_('elasticnet'),
              power_t=np.float64(0.08067506383144306), tol=0.0001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox" checked=""><label for="sk-estimator-id-7" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;SGDClassifier<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.SGDClassifier.html">?<span>Documentation for SGDClassifier</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>SGDClassifier(alpha=np.float64(7.734282955563902e-05),
              epsilon=np.float64(0.004338715346995631),
              eta0=np.float64(0.006251777605333116),
              l1_ratio=np.float64(0.0029250495014144875),
              learning_rate='invscaling', loss=np.str_('modified_huber'),
              n_jobs=-1, penalty=np.str_('elasticnet'),
              power_t=np.float64(0.08067506383144306), tol=0.0001)</pre></div> </div></div></div></div>
</div>
</div>
<div id="cell-73" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:37.251445Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:37.251029Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:37.255341Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:37.254778Z&quot;}" data-execution_count="40">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb52-1"><a href=""></a>metrics.accuracy_score(y_test, y_pred)</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>0.9298245614035088</code></pre>
</div>
</div>
</section>

<section id="setting-the-budget" class="title-slide slide level1 center">
<h1>Setting the budget</h1>
<div id="cell-75" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:37.257149Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:37.256737Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:45.002414Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:45.001776Z&quot;}" data-execution_count="41">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb54-1"><a href=""></a>automl, y_pred <span class="op">=</span> auto_ml(<span class="dv">100</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[flaml.automl.logger: 11-29 15:08:37] {1728} INFO - task = classification
[flaml.automl.logger: 11-29 15:08:37] {1739} INFO - Evaluation method: cv
[flaml.automl.logger: 11-29 15:08:37] {1838} INFO - Minimizing error metric: 1-accuracy
[flaml.automl.logger: 11-29 15:08:37] {1955} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'sgd', 'lrl1']
[flaml.automl.logger: 11-29 15:08:37] {2258} INFO - iteration 0, current learner lgbm
[flaml.automl.logger: 11-29 15:08:37] {2393} INFO - Estimated sufficient time budget=10000s. Estimated necessary time budget=10s.
[flaml.automl.logger: 11-29 15:08:37] {2442} INFO -  at 0.0s,   estimator lgbm's best error=0.1282, best estimator lgbm's best error=0.1282
[flaml.automl.logger: 11-29 15:08:37] {2258} INFO - iteration 1, current learner lgbm
[flaml.automl.logger: 11-29 15:08:37] {2442} INFO -  at 0.1s,   estimator lgbm's best error=0.1282, best estimator lgbm's best error=0.1282
[flaml.automl.logger: 11-29 15:08:37] {2258} INFO - iteration 2, current learner lgbm
[flaml.automl.logger: 11-29 15:08:37] {2442} INFO -  at 0.1s,   estimator lgbm's best error=0.0829, best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:37] {2258} INFO - iteration 3, current learner rf
[flaml.automl.logger: 11-29 15:08:37] {2442} INFO -  at 0.3s,   estimator rf's best error=0.1005,   best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:37] {2258} INFO - iteration 4, current learner lgbm
[flaml.automl.logger: 11-29 15:08:37] {2442} INFO -  at 0.3s,   estimator lgbm's best error=0.0829, best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:37] {2258} INFO - iteration 5, current learner lgbm
[flaml.automl.logger: 11-29 15:08:37] {2442} INFO -  at 0.3s,   estimator lgbm's best error=0.0829, best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:37] {2258} INFO - iteration 6, current learner lgbm
[flaml.automl.logger: 11-29 15:08:37] {2442} INFO -  at 0.4s,   estimator lgbm's best error=0.0829, best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:37] {2258} INFO - iteration 7, current learner lgbm
[flaml.automl.logger: 11-29 15:08:37] {2442} INFO -  at 0.4s,   estimator lgbm's best error=0.0829, best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:37] {2258} INFO - iteration 8, current learner lgbm
[flaml.automl.logger: 11-29 15:08:37] {2442} INFO -  at 0.4s,   estimator lgbm's best error=0.0829, best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:37] {2258} INFO - iteration 9, current learner rf
[flaml.automl.logger: 11-29 15:08:37] {2442} INFO -  at 0.6s,   estimator rf's best error=0.0930,   best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:37] {2258} INFO - iteration 10, current learner xgboost
[flaml.automl.logger: 11-29 15:08:37] {2442} INFO -  at 0.6s,   estimator xgboost's best error=0.1080,  best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:37] {2258} INFO - iteration 11, current learner xgboost
[flaml.automl.logger: 11-29 15:08:37] {2442} INFO -  at 0.7s,   estimator xgboost's best error=0.1080,  best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:37] {2258} INFO - iteration 12, current learner xgboost
[flaml.automl.logger: 11-29 15:08:38] {2442} INFO -  at 0.8s,   estimator xgboost's best error=0.0880,  best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:38] {2258} INFO - iteration 13, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:38] {2442} INFO -  at 0.9s,   estimator extra_tree's best error=0.0955,   best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:38] {2258} INFO - iteration 14, current learner xgboost
[flaml.automl.logger: 11-29 15:08:38] {2442} INFO -  at 1.0s,   estimator xgboost's best error=0.0880,  best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:38] {2258} INFO - iteration 15, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:38] {2442} INFO -  at 1.2s,   estimator extra_tree's best error=0.0955,   best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:38] {2258} INFO - iteration 16, current learner rf
[flaml.automl.logger: 11-29 15:08:38] {2442} INFO -  at 1.3s,   estimator rf's best error=0.0930,   best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:38] {2258} INFO - iteration 17, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:38] {2442} INFO -  at 1.5s,   estimator extra_tree's best error=0.0955,   best estimator lgbm's best error=0.0829
[flaml.automl.logger: 11-29 15:08:38] {2258} INFO - iteration 18, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:38] {2442} INFO -  at 1.6s,   estimator xgb_limitdepth's best error=0.0628,   best estimator xgb_limitdepth's best error=0.0628
[flaml.automl.logger: 11-29 15:08:38] {2258} INFO - iteration 19, current learner lgbm
[flaml.automl.logger: 11-29 15:08:38] {2442} INFO -  at 1.6s,   estimator lgbm's best error=0.0829, best estimator xgb_limitdepth's best error=0.0628
[flaml.automl.logger: 11-29 15:08:38] {2258} INFO - iteration 20, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:38] {2442} INFO -  at 1.7s,   estimator xgb_limitdepth's best error=0.0628,   best estimator xgb_limitdepth's best error=0.0628
[flaml.automl.logger: 11-29 15:08:38] {2258} INFO - iteration 21, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:39] {2442} INFO -  at 1.9s,   estimator extra_tree's best error=0.0955,   best estimator xgb_limitdepth's best error=0.0628
[flaml.automl.logger: 11-29 15:08:39] {2258} INFO - iteration 22, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:39] {2442} INFO -  at 2.0s,   estimator xgb_limitdepth's best error=0.0604,   best estimator xgb_limitdepth's best error=0.0604
[flaml.automl.logger: 11-29 15:08:39] {2258} INFO - iteration 23, current learner sgd
[flaml.automl.logger: 11-29 15:08:39] {2442} INFO -  at 2.1s,   estimator sgd's best error=0.0679,  best estimator xgb_limitdepth's best error=0.0604
[flaml.automl.logger: 11-29 15:08:39] {2258} INFO - iteration 24, current learner xgboost
[flaml.automl.logger: 11-29 15:08:39] {2442} INFO -  at 2.1s,   estimator xgboost's best error=0.0830,  best estimator xgb_limitdepth's best error=0.0604
[flaml.automl.logger: 11-29 15:08:39] {2258} INFO - iteration 25, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:39] {2442} INFO -  at 2.3s,   estimator extra_tree's best error=0.0955,   best estimator xgb_limitdepth's best error=0.0604
[flaml.automl.logger: 11-29 15:08:39] {2258} INFO - iteration 26, current learner sgd
[flaml.automl.logger: 11-29 15:08:39] {2442} INFO -  at 2.4s,   estimator sgd's best error=0.0679,  best estimator xgb_limitdepth's best error=0.0604
[flaml.automl.logger: 11-29 15:08:39] {2258} INFO - iteration 27, current learner sgd
[flaml.automl.logger: 11-29 15:08:39] {2442} INFO -  at 2.4s,   estimator sgd's best error=0.0554,  best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:39] {2258} INFO - iteration 28, current learner lrl1
[flaml.automl.logger: 11-29 15:08:39] {2442} INFO -  at 2.5s,   estimator lrl1's best error=0.0604, best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:39] {2258} INFO - iteration 29, current learner sgd
[flaml.automl.logger: 11-29 15:08:39] {2442} INFO -  at 2.6s,   estimator sgd's best error=0.0554,  best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:39] {2258} INFO - iteration 30, current learner lrl1
[flaml.automl.logger: 11-29 15:08:39] {2442} INFO -  at 2.7s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:39] {2258} INFO - iteration 31, current learner lrl1
[flaml.automl.logger: 11-29 15:08:39] {2442} INFO -  at 2.7s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:39] {2258} INFO - iteration 32, current learner lrl1
[flaml.automl.logger: 11-29 15:08:40] {2442} INFO -  at 2.8s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:40] {2258} INFO - iteration 33, current learner rf
[flaml.automl.logger: 11-29 15:08:40] {2442} INFO -  at 3.0s,   estimator rf's best error=0.0905,   best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:40] {2258} INFO - iteration 34, current learner lgbm
[flaml.automl.logger: 11-29 15:08:40] {2442} INFO -  at 3.0s,   estimator lgbm's best error=0.0829, best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:40] {2258} INFO - iteration 35, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:40] {2442} INFO -  at 3.2s,   estimator extra_tree's best error=0.0955,   best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:40] {2258} INFO - iteration 36, current learner lrl1
[flaml.automl.logger: 11-29 15:08:40] {2442} INFO -  at 3.3s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:40] {2258} INFO - iteration 37, current learner rf
[flaml.automl.logger: 11-29 15:08:40] {2442} INFO -  at 3.4s,   estimator rf's best error=0.0905,   best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:40] {2258} INFO - iteration 38, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:40] {2442} INFO -  at 3.5s,   estimator xgb_limitdepth's best error=0.0604,   best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:40] {2258} INFO - iteration 39, current learner lrl1
[flaml.automl.logger: 11-29 15:08:40] {2442} INFO -  at 3.6s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0554
[flaml.automl.logger: 11-29 15:08:40] {2258} INFO - iteration 40, current learner sgd
[flaml.automl.logger: 11-29 15:08:40] {2442} INFO -  at 3.6s,   estimator sgd's best error=0.0529,  best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:40] {2258} INFO - iteration 41, current learner sgd
[flaml.automl.logger: 11-29 15:08:41] {2442} INFO -  at 3.7s,   estimator sgd's best error=0.0529,  best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:41] {2258} INFO - iteration 42, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:41] {2442} INFO -  at 3.9s,   estimator extra_tree's best error=0.0930,   best estimator sgd's best error=0.0529
[flaml.automl.logger: 11-29 15:08:41] {2258} INFO - iteration 43, current learner sgd
[flaml.automl.logger: 11-29 15:08:41] {2442} INFO -  at 3.9s,   estimator sgd's best error=0.0504,  best estimator sgd's best error=0.0504
[flaml.automl.logger: 11-29 15:08:41] {2258} INFO - iteration 44, current learner sgd
[flaml.automl.logger: 11-29 15:08:41] {2442} INFO -  at 4.0s,   estimator sgd's best error=0.0504,  best estimator sgd's best error=0.0504
[flaml.automl.logger: 11-29 15:08:41] {2258} INFO - iteration 45, current learner lgbm
[flaml.automl.logger: 11-29 15:08:41] {2442} INFO -  at 4.0s,   estimator lgbm's best error=0.0829, best estimator sgd's best error=0.0504
[flaml.automl.logger: 11-29 15:08:41] {2258} INFO - iteration 46, current learner sgd
[flaml.automl.logger: 11-29 15:08:41] {2442} INFO -  at 4.0s,   estimator sgd's best error=0.0504,  best estimator sgd's best error=0.0504
[flaml.automl.logger: 11-29 15:08:41] {2258} INFO - iteration 47, current learner lrl1
[flaml.automl.logger: 11-29 15:08:41] {2442} INFO -  at 4.1s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0504
[flaml.automl.logger: 11-29 15:08:41] {2258} INFO - iteration 48, current learner sgd
[flaml.automl.logger: 11-29 15:08:41] {2442} INFO -  at 4.1s,   estimator sgd's best error=0.0504,  best estimator sgd's best error=0.0504
[flaml.automl.logger: 11-29 15:08:41] {2258} INFO - iteration 49, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:41] {2442} INFO -  at 4.2s,   estimator xgb_limitdepth's best error=0.0604,   best estimator sgd's best error=0.0504
[flaml.automl.logger: 11-29 15:08:41] {2258} INFO - iteration 50, current learner sgd
[flaml.automl.logger: 11-29 15:08:41] {2442} INFO -  at 4.3s,   estimator sgd's best error=0.0504,  best estimator sgd's best error=0.0504
[flaml.automl.logger: 11-29 15:08:41] {2258} INFO - iteration 51, current learner lgbm
[flaml.automl.logger: 11-29 15:08:41] {2442} INFO -  at 4.3s,   estimator lgbm's best error=0.0628, best estimator sgd's best error=0.0504
[flaml.automl.logger: 11-29 15:08:41] {2258} INFO - iteration 52, current learner sgd
[flaml.automl.logger: 11-29 15:08:41] {2442} INFO -  at 4.3s,   estimator sgd's best error=0.0504,  best estimator sgd's best error=0.0504
[flaml.automl.logger: 11-29 15:08:41] {2258} INFO - iteration 53, current learner sgd
[flaml.automl.logger: 11-29 15:08:41] {2442} INFO -  at 4.4s,   estimator sgd's best error=0.0504,  best estimator sgd's best error=0.0504
[flaml.automl.logger: 11-29 15:08:41] {2258} INFO - iteration 54, current learner xgboost
[flaml.automl.logger: 11-29 15:08:41] {2442} INFO -  at 4.5s,   estimator xgboost's best error=0.0805,  best estimator sgd's best error=0.0504
[flaml.automl.logger: 11-29 15:08:41] {2258} INFO - iteration 55, current learner xgboost
[flaml.automl.logger: 11-29 15:08:41] {2442} INFO -  at 4.6s,   estimator xgboost's best error=0.0805,  best estimator sgd's best error=0.0504
[flaml.automl.logger: 11-29 15:08:41] {2258} INFO - iteration 56, current learner lgbm
[flaml.automl.logger: 11-29 15:08:41] {2442} INFO -  at 4.6s,   estimator lgbm's best error=0.0628, best estimator sgd's best error=0.0504
[flaml.automl.logger: 11-29 15:08:41] {2258} INFO - iteration 57, current learner lgbm
[flaml.automl.logger: 11-29 15:08:41] {2442} INFO -  at 4.6s,   estimator lgbm's best error=0.0628, best estimator sgd's best error=0.0504
[flaml.automl.logger: 11-29 15:08:41] {2258} INFO - iteration 58, current learner sgd
[flaml.automl.logger: 11-29 15:08:41] {2442} INFO -  at 4.7s,   estimator sgd's best error=0.0504,  best estimator sgd's best error=0.0504
[flaml.automl.logger: 11-29 15:08:41] {2258} INFO - iteration 59, current learner lgbm
[flaml.automl.logger: 11-29 15:08:41] {2442} INFO -  at 4.7s,   estimator lgbm's best error=0.0628, best estimator sgd's best error=0.0504
[flaml.automl.logger: 11-29 15:08:41] {2258} INFO - iteration 60, current learner xgboost
[flaml.automl.logger: 11-29 15:08:42] {2442} INFO -  at 4.8s,   estimator xgboost's best error=0.0805,  best estimator sgd's best error=0.0504
[flaml.automl.logger: 11-29 15:08:42] {2258} INFO - iteration 61, current learner sgd
[flaml.automl.logger: 11-29 15:08:42] {2442} INFO -  at 4.8s,   estimator sgd's best error=0.0504,  best estimator sgd's best error=0.0504
[flaml.automl.logger: 11-29 15:08:42] {2258} INFO - iteration 62, current learner lgbm
[flaml.automl.logger: 11-29 15:08:42] {2442} INFO -  at 4.9s,   estimator lgbm's best error=0.0603, best estimator sgd's best error=0.0504
[flaml.automl.logger: 11-29 15:08:42] {2258} INFO - iteration 63, current learner sgd
[flaml.automl.logger: 11-29 15:08:42] {2442} INFO -  at 4.9s,   estimator sgd's best error=0.0479,  best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:42] {2258} INFO - iteration 64, current learner rf
[flaml.automl.logger: 11-29 15:08:42] {2442} INFO -  at 5.2s,   estimator rf's best error=0.0854,   best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:42] {2258} INFO - iteration 65, current learner sgd
[flaml.automl.logger: 11-29 15:08:42] {2442} INFO -  at 5.2s,   estimator sgd's best error=0.0479,  best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:42] {2258} INFO - iteration 66, current learner sgd
[flaml.automl.logger: 11-29 15:08:42] {2442} INFO -  at 5.2s,   estimator sgd's best error=0.0479,  best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:42] {2258} INFO - iteration 67, current learner lgbm
[flaml.automl.logger: 11-29 15:08:42] {2442} INFO -  at 5.3s,   estimator lgbm's best error=0.0603, best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:42] {2258} INFO - iteration 68, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:42] {2442} INFO -  at 5.3s,   estimator xgb_limitdepth's best error=0.0604,   best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:42] {2258} INFO - iteration 69, current learner sgd
[flaml.automl.logger: 11-29 15:08:42] {2442} INFO -  at 5.4s,   estimator sgd's best error=0.0479,  best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:42] {2258} INFO - iteration 70, current learner sgd
[flaml.automl.logger: 11-29 15:08:42] {2442} INFO -  at 5.4s,   estimator sgd's best error=0.0479,  best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:42] {2258} INFO - iteration 71, current learner lgbm
[flaml.automl.logger: 11-29 15:08:42] {2442} INFO -  at 5.4s,   estimator lgbm's best error=0.0603, best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:42] {2258} INFO - iteration 72, current learner sgd
[flaml.automl.logger: 11-29 15:08:42] {2442} INFO -  at 5.5s,   estimator sgd's best error=0.0479,  best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:42] {2258} INFO - iteration 73, current learner sgd
[flaml.automl.logger: 11-29 15:08:42] {2442} INFO -  at 5.5s,   estimator sgd's best error=0.0479,  best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:42] {2258} INFO - iteration 74, current learner sgd
[flaml.automl.logger: 11-29 15:08:42] {2442} INFO -  at 5.6s,   estimator sgd's best error=0.0479,  best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:42] {2258} INFO - iteration 75, current learner lrl1
[flaml.automl.logger: 11-29 15:08:42] {2442} INFO -  at 5.6s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:42] {2258} INFO - iteration 76, current learner sgd
[flaml.automl.logger: 11-29 15:08:42] {2442} INFO -  at 5.7s,   estimator sgd's best error=0.0479,  best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:42] {2258} INFO - iteration 77, current learner sgd
[flaml.automl.logger: 11-29 15:08:42] {2442} INFO -  at 5.7s,   estimator sgd's best error=0.0479,  best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:42] {2258} INFO - iteration 78, current learner rf
[flaml.automl.logger: 11-29 15:08:43] {2442} INFO -  at 5.9s,   estimator rf's best error=0.0804,   best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:43] {2258} INFO - iteration 79, current learner rf
[flaml.automl.logger: 11-29 15:08:43] {2442} INFO -  at 6.0s,   estimator rf's best error=0.0804,   best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:43] {2258} INFO - iteration 80, current learner sgd
[flaml.automl.logger: 11-29 15:08:43] {2442} INFO -  at 6.1s,   estimator sgd's best error=0.0479,  best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:43] {2258} INFO - iteration 81, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:43] {2442} INFO -  at 6.2s,   estimator xgb_limitdepth's best error=0.0604,   best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:43] {2258} INFO - iteration 82, current learner rf
[flaml.automl.logger: 11-29 15:08:43] {2442} INFO -  at 6.4s,   estimator rf's best error=0.0804,   best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:43] {2258} INFO - iteration 83, current learner lrl1
[flaml.automl.logger: 11-29 15:08:43] {2442} INFO -  at 6.5s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:43] {2258} INFO - iteration 84, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:43] {2442} INFO -  at 6.6s,   estimator xgb_limitdepth's best error=0.0604,   best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:43] {2258} INFO - iteration 85, current learner sgd
[flaml.automl.logger: 11-29 15:08:43] {2442} INFO -  at 6.6s,   estimator sgd's best error=0.0479,  best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:43] {2258} INFO - iteration 86, current learner sgd
[flaml.automl.logger: 11-29 15:08:43] {2442} INFO -  at 6.7s,   estimator sgd's best error=0.0479,  best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:43] {2258} INFO - iteration 87, current learner sgd
[flaml.automl.logger: 11-29 15:08:43] {2442} INFO -  at 6.7s,   estimator sgd's best error=0.0479,  best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:43] {2258} INFO - iteration 88, current learner sgd
[flaml.automl.logger: 11-29 15:08:44] {2442} INFO -  at 6.8s,   estimator sgd's best error=0.0479,  best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:44] {2258} INFO - iteration 89, current learner sgd
[flaml.automl.logger: 11-29 15:08:44] {2442} INFO -  at 6.8s,   estimator sgd's best error=0.0479,  best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:44] {2258} INFO - iteration 90, current learner xgboost
[flaml.automl.logger: 11-29 15:08:44] {2442} INFO -  at 6.9s,   estimator xgboost's best error=0.0754,  best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:44] {2258} INFO - iteration 91, current learner xgboost
[flaml.automl.logger: 11-29 15:08:44] {2442} INFO -  at 6.9s,   estimator xgboost's best error=0.0754,  best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:44] {2258} INFO - iteration 92, current learner sgd
[flaml.automl.logger: 11-29 15:08:44] {2442} INFO -  at 7.0s,   estimator sgd's best error=0.0479,  best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:44] {2258} INFO - iteration 93, current learner extra_tree
[flaml.automl.logger: 11-29 15:08:44] {2442} INFO -  at 7.2s,   estimator extra_tree's best error=0.0930,   best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:44] {2258} INFO - iteration 94, current learner lrl1
[flaml.automl.logger: 11-29 15:08:44] {2442} INFO -  at 7.3s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:44] {2258} INFO - iteration 95, current learner sgd
[flaml.automl.logger: 11-29 15:08:44] {2442} INFO -  at 7.3s,   estimator sgd's best error=0.0479,  best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:44] {2258} INFO - iteration 96, current learner sgd
[flaml.automl.logger: 11-29 15:08:44] {2442} INFO -  at 7.3s,   estimator sgd's best error=0.0479,  best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:44] {2258} INFO - iteration 97, current learner rf
[flaml.automl.logger: 11-29 15:08:44] {2442} INFO -  at 7.6s,   estimator rf's best error=0.0804,   best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:44] {2258} INFO - iteration 98, current learner lrl1
[flaml.automl.logger: 11-29 15:08:44] {2442} INFO -  at 7.7s,   estimator lrl1's best error=0.0579, best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:44] {2258} INFO - iteration 99, current learner xgb_limitdepth
[flaml.automl.logger: 11-29 15:08:44] {2442} INFO -  at 7.7s,   estimator xgb_limitdepth's best error=0.0604,   best estimator sgd's best error=0.0479
[flaml.automl.logger: 11-29 15:08:44] {2685} INFO - retrain sgd for 0.0s
[flaml.automl.logger: 11-29 15:08:44] {2688} INFO - retrained model: SGDClassifier(alpha=np.float64(7.908742211719659e-06),
              epsilon=np.float64(0.026287106310941128),
              eta0=np.float64(0.004395780757259997), learning_rate='invscaling',
              loss=np.str_('modified_huber'), n_jobs=-1, penalty=np.str_('l2'),
              power_t=np.float64(0.021268346029650637), tol=0.0001)
[flaml.automl.logger: 11-29 15:08:44] {1985} INFO - fit succeeded
[flaml.automl.logger: 11-29 15:08:44] {1986} INFO - Time taken to find the best model: 4.913948059082031</code></pre>
</div>
</div>
<div id="cell-76" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-11-29T15:08:45.004360Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-11-29T15:08:45.004017Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-11-29T15:08:45.008463Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-11-29T15:08:45.007900Z&quot;}" data-execution_count="42">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb56-1"><a href=""></a>metrics.accuracy_score(y_test, y_pred)</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>0.9415204678362573</code></pre>
</div>
</div>
<div class="quarto-auto-generated-content">
<div class="footer footer-default">
<p>Matteo Francia - Machine Learning and Data Mining (Module 2) - A.Y. 2024/25</p>
</div>
</div>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="lab-09-breastcancer.solution_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="lab-09-breastcancer.solution_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="lab-09-breastcancer.solution_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="lab-09-breastcancer.solution_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="lab-09-breastcancer.solution_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="lab-09-breastcancer.solution_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="lab-09-breastcancer.solution_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="lab-09-breastcancer.solution_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="lab-09-breastcancer.solution_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="lab-09-breastcancer.solution_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: true,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'bottom-right',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1100,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>